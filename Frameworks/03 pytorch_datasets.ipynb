{"cells":[{"cell_type":"markdown","metadata":{"id":"7VI4fFKqqhIs"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/029_pytorch_datasets/pytorch_datasets.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"FjFFQJmWqhIw"},"source":["# Pytorch - Datasets"]},{"cell_type":"markdown","metadata":{"id":"Qx1GRqiSqhIx"},"source":["En los posts anteriores hemos introducido los conceptos fundamentales de la librería de `Deep Learning` `Pytorch` y también hemos visto la funcionalidad que nos ofrece a la hora de diseñar y entrenar `redes neuronales`. En este post nos enfocamos en la herramientas que la librería nos da a la hora definir nuestros *datasets*."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:17:52.168031Z","start_time":"2020-08-15T13:17:51.679881Z"},"id":"nAHiD268qhIx"},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","metadata":{"id":"fGNLgMR7qhIz"},"source":["## Iterando tensores"]},{"cell_type":"markdown","metadata":{"id":"kZ9DssmiqhIz"},"source":["En los posts anteriores hemos utilizado el dataset MNIST para ilustrar los diferentes ejemplos que hemos visto. Vamos a seguir con este caso. A continuación tenemos una implementación en la que iteramos por los datos de manera explícita para entrenar nuestra red."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:12.317390Z","start_time":"2020-08-15T13:17:52.169393Z"},"id":"Kf3B49IyqhI0","executionInfo":{"status":"ok","timestamp":1678244307588,"user_tz":240,"elapsed":49324,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee30b96e-1ca0-41d1-deab-5b3a226a2658"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}],"source":["from sklearn.datasets import fetch_openml\n","import numpy as np\n","# descarga datos\n","\n","mnist = fetch_openml('mnist_784', version=1)\n","X, Y = mnist[\"data\"], mnist[\"target\"]"]},{"cell_type":"code","source":["# X_train, X_test, y_train, y_test = X[:60000] / 255., X[60000:] / 255., Y[:60000].astype(np.int), Y[60000:].astype(np.int)\n","x_2=np.array(X)\n","y_2=np.array(Y)\n","\n","# normalización y split\n","\n","X_train =x_2[:60000] / 255.\n","X_test =x_2[60000:] / 255.\n","y_train = y_2[:60000].astype(np.int)\n","y_test = y_2[60000:].astype(np.int)\n","\n","\n","X_t = torch.from_numpy(X_train).float().cuda()\n","Y_t = torch.from_numpy(y_train).long().cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXR1_xNoUyg7","executionInfo":{"status":"ok","timestamp":1678244312766,"user_tz":240,"elapsed":5183,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"32cc4d6a-a341-4be7-9cf2-47123883eecc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-55254b285873>:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y_train = y_2[:60000].astype(np.int)\n","<ipython-input-3-55254b285873>:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y_test = y_2[60000:].astype(np.int)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:12.348390Z","start_time":"2020-08-15T13:18:12.319392Z"},"id":"DSH7GEmUqhI1"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","def softmax(x):\n","    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n","\n","def evaluate(x):\n","    model.eval()\n","    y_pred = model(x)\n","    y_probas = softmax(y_pred)\n","    return torch.argmax(y_probas, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:13.829898Z","start_time":"2020-08-15T13:18:12.349391Z"},"code_folding":[15],"id":"CmWA6s9hqhI1","outputId":"68f2b772-5be8-4a49-dd87-6c3c19ee1cf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678244315663,"user_tz":240,"elapsed":2900,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 10/100 Loss 1.72281\n","Epoch 20/100 Loss 1.42174\n","Epoch 30/100 Loss 1.20077\n","Epoch 40/100 Loss 1.01855\n","Epoch 50/100 Loss 0.89915\n","Epoch 60/100 Loss 0.80804\n","Epoch 70/100 Loss 0.73562\n","Epoch 80/100 Loss 0.67904\n","Epoch 90/100 Loss 0.63344\n","Epoch 100/100 Loss 0.59591\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9278"]},"metadata":{},"execution_count":5}],"source":["D_in, H, D_out = 784, 100, 10\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",").to(\"cuda\")\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n","\n","epochs = 100\n","log_each = 10\n","l = []\n","model.train()\n","for e in range(1, epochs+1):\n","\n","    # forward\n","    y_pred = model(X_t)\n","\n","    # loss\n","    loss = criterion(y_pred, Y_t)\n","    l.append(loss.item())\n","\n","    # ponemos a cero los gradientes\n","    optimizer.zero_grad()\n","\n","    # Backprop (calculamos todos los gradientes automáticamente)\n","    loss.backward()\n","\n","    # update de los pesos\n","    optimizer.step()\n","\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"id":"p9cLYR_jqhI3"},"source":["## Iterando por *Batches*"]},{"cell_type":"markdown","metadata":{"id":"--FStgZhqhI3"},"source":["En la implementación anterior estamos optimizando nuestro modelo con el algoritmo de `batch gradient descent`, en el que utilizamos todos nuestros datos en cada paso de optimización. Sin embargo, un algoritmo que puede converger más rápido (y única opción si nuestro dataset es tan grande que no cabe en memoria) es el de `mini-batch gradient descent` (el cual hemos ya utilizado en posts anteriores)."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:17.723943Z","start_time":"2020-08-15T13:18:13.830897Z"},"code_folding":[17],"id":"6IqRUzSEqhI4","outputId":"a9b748e9-e099-44f2-9883-91ebe3aa88f9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678244322243,"user_tz":240,"elapsed":5688,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10 Loss 0.30976\n","Epoch 2/10 Loss 0.21584\n","Epoch 3/10 Loss 0.17284\n","Epoch 4/10 Loss 0.14693\n","Epoch 5/10 Loss 0.12884\n","Epoch 6/10 Loss 0.11504\n","Epoch 7/10 Loss 0.10409\n","Epoch 8/10 Loss 0.09515\n","Epoch 9/10 Loss 0.08760\n","Epoch 10/10 Loss 0.08120\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9702"]},"metadata":{},"execution_count":6}],"source":["D_in, H, D_out = 784, 100, 10\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",").to(\"cuda\")\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n","\n","epochs = 10\n","batch_size = 100\n","log_each = 1\n","l = []\n","model.train()\n","batches = len(X_t) // batch_size\n","for e in range(1, epochs+1):\n","\n","    _l = []\n","    # iteramos por batches\n","    for b in range(batches):\n","        x_b = X_t[b*batch_size:(b+1)*batch_size]\n","        y_b = Y_t[b*batch_size:(b+1)*batch_size]\n","\n","        # forward\n","        y_pred = model(x_b)\n","\n","        # loss\n","        loss = criterion(y_pred, y_b)\n","        _l.append(loss.item())\n","\n","        # ponemos a cero los gradientes\n","        optimizer.zero_grad()\n","\n","        # Backprop (calculamos todos los gradientes automáticamente)\n","        loss.backward()\n","\n","        # update de los pesos\n","        optimizer.step()\n","\n","    l.append(np.mean(_l))\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"id":"bfbouE7WqhI5"},"source":["Si bien esta implementación es correcta y funcional, dependiendo de nuestros datos puede llegar a complicarse mucho (por ejemplo, si necesitamos cargar muchas imágenes a las cuales queremos aplicar transformaciones, juntar en batches, etc...). Además, es común reutilizar la lógica para cargar nuestros datos no sólo para entrenar la red, si no para generar predicciones. Este hecho motiva el uso de las clases especiales que `Pytorch` nos ofrece para ello."]},{"cell_type":"markdown","metadata":{"id":"MSGOAhTWqhI5"},"source":["## La clase *Dataset*"]},{"cell_type":"markdown","metadata":{"id":"Mb6WxFXWqhI5"},"source":["La primera clase que tenemos que conocer es la clase `Dataset`. Esta clase hereda de la clase madre `torch.utils.data.Dataset` y tenemos que definir, como mínimo, tres funciones:\n","\n","- `__init__`: el constructor\n","- `__len__`: devuelve el número de muestras en el dataset\n","- `__getitem__`: devuelve una muestra en concreto del dataset\n","\n","Una vez definida la clase, ésta puede usarse como si de cualquier iterador se tratase."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:21:45.397959Z","start_time":"2020-08-15T13:21:45.390960Z"},"id":"YIXmp0UGqhI5"},"outputs":[],"source":["# clase Dataset, hereda de la clase `torch.utils.data.Dataset`\n","# class DSPerros(torch.utils.data.Dataset):\n","\n","class DatasetPersonalizado(torch.utils.data.Dataset):\n","    # constructor\n","    def __init__(self, X, Y):\n","        self.X = torch.from_numpy(X).float().cuda()\n","        self.Y = torch.from_numpy(Y).long().cuda()\n","    # devolvemos el número de datos en el dataset\n","    def __len__(self):\n","        return len(self.X)\n","        # return len(self.Y)\n","    # devolvemos el elemento `ix` del dataset\n","    def __getitem__(self, ix):\n","        return self.X[ix], self.Y[ix]"]},{"cell_type":"markdown","metadata":{"id":"7kDtghi2qhI6"},"source":["Una vez definida la clase, podemos instanciar un objeto que podemos usar para iterar por nuestros datos."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:21:47.171999Z","start_time":"2020-08-15T13:21:47.074000Z"},"id":"82ljNdg0qhI6","outputId":"19a41f89-99a1-413e-89bc-ebd2737284fa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678244322722,"user_tz":240,"elapsed":488,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["60000"]},"metadata":{},"execution_count":8}],"source":["dataset = DatasetPersonalizado(X_train, y_train)\n","\n","len(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:21:52.775576Z","start_time":"2020-08-15T13:21:48.951127Z"},"code_folding":[2,17],"id":"szluP5ZQqhI6","outputId":"428ce8a7-d760-4e96-a5c5-80917ed16b61","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678244328511,"user_tz":240,"elapsed":5791,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10 Loss 0.30880\n","Epoch 2/10 Loss 0.21684\n","Epoch 3/10 Loss 0.17500\n","Epoch 4/10 Loss 0.14924\n","Epoch 5/10 Loss 0.13095\n","Epoch 6/10 Loss 0.11689\n","Epoch 7/10 Loss 0.10558\n","Epoch 8/10 Loss 0.09627\n","Epoch 9/10 Loss 0.08836\n","Epoch 10/10 Loss 0.08155\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9736"]},"metadata":{},"execution_count":9}],"source":["D_in, H, D_out = 784, 100, 10\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",").to(\"cuda\")\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n","\n","epochs = 10\n","batch_size = 100\n","log_each = 1\n","l = []\n","model.train()\n","batches = len(dataset) // batch_size\n","for e in range(1, epochs+1):\n","\n","    _l = []\n","    # iteramos por batches en el dataset\n","    for b in range(batches):\n","        x_b, y_b = dataset[b*batch_size:(b+1)*batch_size]\n","\n","        # forward\n","        y_pred = model(x_b)\n","\n","        # loss\n","        loss = criterion(y_pred, y_b)\n","        _l.append(loss.item())\n","\n","        # ponemos a cero los gradientes\n","        optimizer.zero_grad()\n","\n","        # Backprop (calculamos todos los gradientes automáticamente)\n","        loss.backward()\n","\n","        # update de los pesos\n","        optimizer.step()\n","\n","    l.append(np.mean(_l))\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"id":"XV2nVro3qhI7"},"source":["Podemos iterar directamente sobre el objeto `dataset` de la misma manera que hacíamos anteriormente, sin embargo `Pytorch` no ofrece otro objeto que nos facilita las cosas a la hora de iterar por batches."]},{"cell_type":"markdown","metadata":{"id":"Z1Wo3qx6qhI7"},"source":["## La clase *DataLoader*"]},{"cell_type":"markdown","metadata":{"id":"iWsjciqnqhI7"},"source":["La clase `DataLoader` recibe un `Dataset` e implementa la lógica para iterar nuestros datos en batches."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:21.690663Z","start_time":"2020-08-15T13:18:21.675664Z"},"id":"kilkig6LqhI7"},"outputs":[],"source":["dataloader = torch.utils.data.DataLoader(dataset, batch_size=62, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:21.706666Z","start_time":"2020-08-15T13:18:21.691664Z"},"id":"U3Q3311HqhI8","outputId":"9618dad8-b3a2-43ed-d47f-f5c78cff9cef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678244328512,"user_tz":240,"elapsed":6,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([62, 784]), torch.Size([62]))"]},"metadata":{},"execution_count":11}],"source":["x, y = next(iter(dataloader))\n","\n","x.shape, y.shape\n","# x[0], y[0]\n","\n","# x, y = next(iter(dataloader))\n","# x.shape, y.shape\n","# x[0], y[0]"]},{"cell_type":"markdown","metadata":{"id":"u7BlxvXtqhI8"},"source":["También permite mezclar los datos al principio de cada epoch con el parámetro `shuffle`, de manera automática carga nuestros datos de manera optimizada utilizando varios *cores* de nuestra CPU si es posible, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:33.617368Z","start_time":"2020-08-15T13:18:21.708665Z"},"code_folding":[15,19],"id":"OaOwPTKxqhI8","outputId":"387e554f-5839-4c60-fd07-e3962f8fb87c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678244343225,"user_tz":240,"elapsed":14716,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10 Loss 0.27341\n","Epoch 2/10 Loss 0.19574\n","Epoch 3/10 Loss 0.15993\n","Epoch 4/10 Loss 0.13749\n","Epoch 5/10 Loss 0.12182\n","Epoch 6/10 Loss 0.11021\n","Epoch 7/10 Loss 0.10045\n","Epoch 8/10 Loss 0.09218\n","Epoch 9/10 Loss 0.08550\n","Epoch 10/10 Loss 0.07964\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9751"]},"metadata":{},"execution_count":12}],"source":["D_in, H, D_out = 784, 100, 10\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",").to(\"cuda\")\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n","\n","epochs = 10\n","log_each = 1\n","l = []\n","model.train()\n","for e in range(1, epochs+1):\n","\n","    _l = []\n","    # iteramos por batches en el dataloader\n","    for x_b, y_b in dataloader:\n","\n","        # forward\n","        y_pred = model(x_b)\n","\n","        # loss\n","        loss = criterion(y_pred, y_b)\n","        _l.append(loss.item())\n","\n","        # ponemos a cero los gradientes\n","        optimizer.zero_grad()\n","\n","        # Backprop (calculamos todos los gradientes automáticamente)\n","        loss.backward()\n","\n","        # update de los pesos\n","        optimizer.step()\n","\n","    l.append(np.mean(_l))\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"id":"C9i9OmmQqhI8"},"source":["También permite definir nuestra propia lógica para crear los batches, algo que puede ser útil en ciertas ocasiones."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:33.633369Z","start_time":"2020-08-15T13:18:33.618369Z"},"id":"AgBLI1sEqhI9"},"outputs":[],"source":["def collate_fn(batch):\n","    return torch.stack([x for x, y in batch]), torch.stack([y for x, y in batch]), torch.stack([2.*x for x, y in batch])"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:33.649369Z","start_time":"2020-08-15T13:18:33.634370Z"},"id":"waqR8RfSqhI9"},"outputs":[],"source":["dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T13:18:52.194888Z","start_time":"2020-08-15T13:18:33.650371Z"},"code_folding":[],"id":"BtchRSLiqhI9","outputId":"84355ca7-d9ac-47c9-822c-27b631a14a24","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"error","timestamp":1678244343713,"user_tz":240,"elapsed":499,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-b8f40df6506c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# iteramos por batches en el dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# no usamos x2_b, sólo es para ver un ejemplo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["D_in, H, D_out = 784, 100, 10\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",").to(\"cuda\")\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n","\n","epochs = 10\n","log_each = 1\n","l = []\n","model.train()\n","for e in range(1, epochs+1):\n","\n","    _l = []\n","    # iteramos por batches en el dataloader\n","    # no usamos x2_b, sólo es para ver un ejemplo\n","    for x_b, y_b in dataloader:\n","\n","        # forward\n","        y_pred = model(x_b)\n","\n","        # loss\n","        loss = criterion(y_pred, y_b)\n","        _l.append(loss.item())\n","\n","        # ponemos a cero los gradientes\n","        optimizer.zero_grad()\n","\n","        # Backprop (calculamos todos los gradientes automáticamente)\n","        loss.backward()\n","\n","        # update de los pesos\n","        optimizer.step()\n","\n","    l.append(np.mean(_l))\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"id":"O9uM6JWZqhI9"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"Cg4Vj2LJqhI9"},"source":["En este post hemos visto diferentes maneras en las que podemos iterar por nuestros datos para entrenar un modelo en `Pytorch`. Si nuestro dataset es sencillo y podemos representarlo como un simple `array` de `NumPy` podemos iterar directamente el `array`, transformándolo previamente en un `tensor`. Sin embargo, cuando nuestro dataset sea más grande y no quepa en memoria o necesite cierto pre-proceso o transformaciones, es muy conveniente utilizar las clases que `Pytorch` nos ofrece para ello. Estas clases son, principalmente, el `Dataset` y el `DataLoader`, las cuales nos van a permitir iterar por nuestros datos de manera eficiente y generar *batches* de forma sencilla (además de otras funcionalidades como mezclar los datos al principio de cada epoch, cargar datos en paralelo, etc)."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/029_pytorch_datasets/pytorch_datasets.ipynb","timestamp":1649228282845}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}