{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"generacion de caracteres RNN.ipynb","provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/037_charRNN/charRNN.ipynb","timestamp":1623376231027}],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hL8a1ozow1HY"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/037_charRNN/charRNN.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"uPaZ4nOJw1Hc"},"source":["# Generaci√≥n de texto"]},{"cell_type":"markdown","metadata":{"id":"Z58oAqNZw1Hd"},"source":["En este post vamos a entrenar una `red neuronal recurrente` para generar texto, car√°cter a car√°cter, inspirado en [CharRNN](https://github.com/karpathy/char-rnn). Nuestra red neuronal recibir√° como entrada una secuencia de letras y deber√° dar como salida la siguiente letra (la cual a√±adiremos a las entradas para volver a generar un nuevo car√°cter). "]},{"cell_type":"markdown","metadata":{"id":"M2908ZEFw1Hd"},"source":["## Los datos"]},{"cell_type":"markdown","metadata":{"id":"hfPBdDTKw1He"},"source":["Lo primero que necesitamos para lograr nuestro objetivo es un conjunto de datos. En este caso, al querer generar texto, nos servir√° con un archivo con mucho texto que queramos imitar. Para ello descargaremos *Don Quijote de la Mancha*, la obra principal del escritor Miguel de Cervantes y una de las m√°s relevantes en la literatura castellana. "]},{"cell_type":"code","metadata":{"id":"k1EKa9iUtsnC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981711721,"user_tz":240,"elapsed":5761,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"02a692ab-6b47-4963-e98f-e1cbcdff2d48"},"source":["!pip install wget"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=34dc6a059f68f086d014a10ad24301662e0a9995daa627860770d15ccde41234\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:39.405968Z","start_time":"2020-08-31T14:37:38.446954Z"},"id":"qiJjUTCzw1He","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1623981712476,"user_tz":240,"elapsed":757,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"10a5a83e-bece-4c8f-b57b-438edc0b807a"},"source":["import wget\n","\n","wget.download('https://mymldatasets.s3.eu-de.cloud-object-storage.appdomain.cloud/el_quijote.txt')"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'el_quijote.txt'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:39.437968Z","start_time":"2020-08-31T14:37:39.406971Z"},"id":"qL_J6MNSw1Hg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981712477,"user_tz":240,"elapsed":13,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"cfc16b72-8cd3-4ce8-dbc7-81ad2833e330"},"source":["f = open(\"el_quijote.txt\", \"r\", encoding='utf-8')\n","text = f.read()\n","text[:300], len(text)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('DON QUIJOTE DE LA MANCHA\\nMiguel de Cervantes Saavedra\\n\\nPRIMERA PARTE\\nCAPIÃÅTULO 1: Que trata de la condicioÃÅn y ejercicio del famoso hidalgo D. Quijote de la Mancha\\nEn un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que viviÃÅa un hidalgo de los de lanza en astillero, ada',\n"," 1038397)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"ZxvAhQWDw1Hg"},"source":["Tenemos alrededor de 1 mill√≥n de car√°cteres en nuestro dataset, suficientes para generar texto de manera convincente como si fu√©semos el manco de Lepanto."]},{"cell_type":"markdown","metadata":{"id":"YbIETvQ2w1Hh"},"source":["## Tokenizaci√≥n"]},{"cell_type":"markdown","metadata":{"id":"meTT950Uw1Hh"},"source":["Para poder darle este texto a nuestra red neuronal necesitamos transformarlo en n√∫meros con los que podemos llevar a cabo las operaciones que tienen lugar en la red. Este proceso se conoce como `tokenizaci√≥n`. Existen muchas formas de llevar a cabo este proceso, en este caso simplemente sustituiremos cada car√°cter en nuestro texto por su posici√≥n en el siguiente vector de car√°cteres."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:39.453968Z","start_time":"2020-08-31T14:37:39.440969Z"},"id":"-F_XsP5Dw1Hi","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1623981712477,"user_tz":240,"elapsed":11,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"35d9f88d-5654-48f2-9780-e4a3a062c55e"},"source":["import string\n","\n","print(string.printable)\n","all_characters = string.printable + \"√±√ë√°√Å√©√â√≠√ç√≥√ì√∫√ö¬ø¬°\"\n","all_characters"],"execution_count":4,"outputs":[{"output_type":"stream","text":["0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n","\r\u000b\f\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c√±√ë√°√Å√©√â√≠√ç√≥√ì√∫√ö¬ø¬°'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:39.469968Z","start_time":"2020-08-31T14:37:39.454970Z"},"id":"eQrpmNJJw1Hi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981712478,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"50f50c39-6ac2-4153-c489-fb1806668065"},"source":["import string\n","\n","class Tokenizer(): \n","    \n","  def __init__(self):\n","    self.all_characters = all_characters\n","    self.n_characters = len(self.all_characters)\n","    \n","  def text_to_seq(self, string):\n","    seq = []\n","    for c in range(len(string)):\n","        try:\n","            seq.append(self.all_characters.index(string[c]))\n","        except:\n","            continue\n","    return seq\n","\n","  def seq_to_text(self, seq):\n","    text = ''\n","    for c in range(len(seq)):\n","        text += self.all_characters[seq[c]]\n","    return text\n","\n","tokenizer = Tokenizer()\n","tokenizer.n_characters"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["114"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"tXswjahTw1Hj"},"source":["El tokenizer puede convertir una secuencia de texto en n√∫meros, y al rev√©s."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:39.485968Z","start_time":"2020-08-31T14:37:39.470969Z"},"id":"SqxgpQu6w1Hj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981712478,"user_tz":240,"elapsed":8,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"6f691fb9-6a48-43bd-fcd7-8baf1b22bed8"},"source":["tokenizer.text_to_seq('se√±or, ¬øqu√© tal?')"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[28, 14, 100, 24, 27, 73, 94, 112, 26, 30, 104, 94, 29, 10, 21, 82]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:39.501968Z","start_time":"2020-08-31T14:37:39.486970Z"},"id":"QjayyHi8w1Hk","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1623981712478,"user_tz":240,"elapsed":7,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"80123ac2-4732-4f00-d836-3045c8deab5d"},"source":["tokenizer.seq_to_text([28, 14, 100, 24, 27, 73, 94, 112, 26, 30, 104, 94, 29, 10, 21, 82])"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'se√±or, ¬øqu√© tal?'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"q__ysE5cw1Hk"},"source":["Ahora podemos tokenizar todo el texto."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:39.756970Z","start_time":"2020-08-31T14:37:39.503970Z"},"id":"JbEB_1tDw1Hk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981712866,"user_tz":240,"elapsed":394,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"343cec19-0fa5-4925-a7d7-3b25ec0bab89"},"source":["text_encoded = tokenizer.text_to_seq(text)\n","print(text_encoded[700:750])\n","print(tokenizer.seq_to_text(text_encoded[700:750]))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[18, 94, 13, 14, 94, 21, 24, 94, 22, 10, 28, 94, 15, 18, 23, 24, 75, 94, 55, 14, 23, 18, 10, 94, 14, 23, 94, 28, 30, 94, 12, 10, 28, 10, 94, 30, 23, 10, 94, 10, 22, 10, 94, 26, 30, 14, 94, 25, 10, 28]\n","i de lo mas fino. Tenia en su casa una ama que pas\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aWXz12SIw1Hk"},"source":["> üí° Pese a que podemos implementar nuestra l√≥gica de tokenizaci√≥n para trabajar a nivel de car√°cteres, cuando trabajamos con palabras completas el proceso puede complicarse. Es por esto que existen muchas herramientas que ya implementan este tipo de procesado (y muchos otros) que podemos utilizar. Un ejemplo, especialmente integrado con `Pytorch`, es la librer√≠a [torchtext](https://pytorch.org/text/)."]},{"cell_type":"markdown","metadata":{"id":"uxmGKLKow1Hl"},"source":["## El *Dataset*"]},{"cell_type":"markdown","metadata":{"id":"yRwLqkQAw1Hl"},"source":["En primer lugar, vamos a separar nuestro texto en un conjunto de entrenamiento y otro de test. C√≥mo ya hemos hablado en posts anteriores, usaremos los datos de entrenamiento para entrenar nuestra red neuronal y los datos de test para calcular las m√©tricas finales."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:39.772968Z","start_time":"2020-08-31T14:37:39.757969Z"},"id":"ZMf3Ix54w1Hl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981712867,"user_tz":240,"elapsed":6,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"ace3f3e3-113f-49c9-8d62-3bce2dfc1a47"},"source":["train_size = len(text_encoded) * 80 // 100 \n","train = text_encoded[:train_size]\n","test = text_encoded[train_size:]\n","print(len(text_encoded))\n","len(train), len(test)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["1017582\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(814065, 203517)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"d2QiBwxdw1Hm"},"source":["Para entrenar nuestra red, vamos a necesitar secuencias de texto de una longitud determinada. Podemos generar estas ventanas con la siguiente funci√≥n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:42.399028Z","start_time":"2020-08-31T14:37:39.773969Z"},"id":"HRt0uy8bw1Hm","executionInfo":{"status":"ok","timestamp":1623981712867,"user_tz":240,"elapsed":4,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}}},"source":["import random\n","\n","def windows(text, window_size = 100):\n","    start_index = 0\n","    end_index = len(text) - window_size\n","    text_windows = []\n","    while start_index < end_index:\n","      text_windows.append(text[start_index:start_index+window_size+1])\n","      start_index += 1\n","    return text_windows"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"PoT0AJka3Ccx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981718114,"user_tz":240,"elapsed":5250,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"0749ffa7-8567-4367-ed3e-179c8716b2f0"},"source":["text_encoded_windows = windows(text_encoded, window_size=100)\n","\n","print(len(text_encoded_windows))\n","print(text_encoded_windows[1016579])\n","print(text_encoded_windows[1016580])\n","print(text_encoded_windows[1016581])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["1017482\n","[10, 23, 28, 24, 73, 96, 34, 94, 10, 21, 94, 15, 18, 23, 94, 25, 10, 27, 10, 18, 28, 94, 14, 23, 94, 28, 24, 22, 11, 27, 10, 73, 94, 14, 23, 94, 17, 30, 22, 24, 73, 94, 14, 23, 94, 28, 30, 14, 23, 24, 96, 39, 40, 47, 94, 38, 36, 38, 43, 44, 39, 44, 36, 37, 47, 50, 73, 94, 36, 38, 36, 39, 40, 48, 44, 38, 50, 94, 39, 40, 94, 47, 36, 94, 36, 53, 42, 36, 48, 36, 54, 44, 47, 47, 36, 73, 94, 40, 49, 94, 47]\n","[23, 28, 24, 73, 96, 34, 94, 10, 21, 94, 15, 18, 23, 94, 25, 10, 27, 10, 18, 28, 94, 14, 23, 94, 28, 24, 22, 11, 27, 10, 73, 94, 14, 23, 94, 17, 30, 22, 24, 73, 94, 14, 23, 94, 28, 30, 14, 23, 24, 96, 39, 40, 47, 94, 38, 36, 38, 43, 44, 39, 44, 36, 37, 47, 50, 73, 94, 36, 38, 36, 39, 40, 48, 44, 38, 50, 94, 39, 40, 94, 47, 36, 94, 36, 53, 42, 36, 48, 36, 54, 44, 47, 47, 36, 73, 94, 40, 49, 94, 47, 36]\n","[28, 24, 73, 96, 34, 94, 10, 21, 94, 15, 18, 23, 94, 25, 10, 27, 10, 18, 28, 94, 14, 23, 94, 28, 24, 22, 11, 27, 10, 73, 94, 14, 23, 94, 17, 30, 22, 24, 73, 94, 14, 23, 94, 28, 30, 14, 23, 24, 96, 39, 40, 47, 94, 38, 36, 38, 43, 44, 39, 44, 36, 37, 47, 50, 73, 94, 36, 38, 36, 39, 40, 48, 44, 38, 50, 94, 39, 40, 94, 47, 36, 94, 36, 53, 42, 36, 48, 36, 54, 44, 47, 47, 36, 73, 94, 40, 49, 94, 47, 36, 94]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zquM9b6Pw1Hm"},"source":["Como puedes ver, hemos generado un n√∫mero determinado de frases con la longitud especificada las cuales empiezan cada vez un car√°cter m√°s a la derecha."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:42.415028Z","start_time":"2020-08-31T14:37:42.400029Z"},"id":"vEBBAjclw1Hn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981718114,"user_tz":240,"elapsed":3,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"d813a5d9-5ef4-4855-f139-bc923f4f290e"},"source":["# print(tokenizer.seq_to_text((text_encoded_windows[0])))\n","# print()\n","# print(tokenizer.seq_to_text((text_encoded_windows[1])))\n","# print()\n","# print(tokenizer.seq_to_text((text_encoded_windows[2])))\n","\n","\n","# torch.tensor(\n","print(text_encoded_windows[10][:])\n","print(\"-\"*10)\n","print(text_encoded_windows[10][:-1])\n","# torch.tensor(\n","print(\"-\"*10)\n","print(text_encoded_windows[10][-1])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[40, 94, 39, 40, 94, 47, 36, 94, 48, 36, 49, 38, 43, 36, 96, 48, 18, 16, 30, 14, 21, 94, 13, 14, 94, 38, 14, 27, 31, 10, 23, 29, 14, 28, 94, 54, 10, 10, 31, 14, 13, 27, 10, 96, 96, 51, 53, 44, 48, 40, 53, 36, 94, 51, 36, 53, 55, 40, 96, 38, 36, 51, 44, 55, 56, 47, 50, 94, 1, 77, 94, 52, 30, 14, 94, 29, 27, 10, 29, 10, 94, 13, 14, 94, 21, 10, 94, 12, 24, 23, 13, 18, 12, 18, 24, 23, 94, 34, 94, 14, 19]\n","----------\n","[40, 94, 39, 40, 94, 47, 36, 94, 48, 36, 49, 38, 43, 36, 96, 48, 18, 16, 30, 14, 21, 94, 13, 14, 94, 38, 14, 27, 31, 10, 23, 29, 14, 28, 94, 54, 10, 10, 31, 14, 13, 27, 10, 96, 96, 51, 53, 44, 48, 40, 53, 36, 94, 51, 36, 53, 55, 40, 96, 38, 36, 51, 44, 55, 56, 47, 50, 94, 1, 77, 94, 52, 30, 14, 94, 29, 27, 10, 29, 10, 94, 13, 14, 94, 21, 10, 94, 12, 24, 23, 13, 18, 12, 18, 24, 23, 94, 34, 94, 14]\n","----------\n","19\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y8IqqnrTw1Hn"},"source":["Nuestro *dataset* de `Pytorch` se encargar√° de darnos cada una de estas frases, utilizando todos los car√°cteres excepto el √∫ltimo como entradas para la red y el √∫ltimo car√°cter como la etiqueta que usaremos durante el entrenamiento (la red deber√° predecir la siguiente letra)."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:43.505162Z","start_time":"2020-08-31T14:37:42.416029Z"},"id":"cF4wItCyw1Hn","executionInfo":{"status":"ok","timestamp":1623981719792,"user_tz":240,"elapsed":1680,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}}},"source":["import torch\n","\n","class CharRNNDataset(torch.utils.data.Dataset):\n","  def __init__(self, text_encoded_windows, train=True):\n","    self.text = text_encoded_windows\n","    self.train = train\n","\n","  def __len__(self):\n","    return len(self.text)\n","\n","  def __getitem__(self, ix):\n","    if self.train:\n","      return torch.tensor(self.text[ix][:-1]), torch.tensor(self.text[ix][-1])\n","    return torch.tensor(self.text[ix])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:46.441198Z","start_time":"2020-08-31T14:37:43.506164Z"},"id":"9vl_v3i0w1Hn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981725049,"user_tz":240,"elapsed":5258,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"489e8062-b185-4a04-88ab-47c18e9fa505"},"source":["train_text_encoded_windows = windows(train)\n","test_text_encoded_windows = windows(test)\n","\n","dataset = {\n","    'train': CharRNNDataset(train_text_encoded_windows),\n","    'val': CharRNNDataset(test_text_encoded_windows)\n","}\n","\n","dataloader = {\n","    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=512, shuffle=True, pin_memory=True),\n","    'val': torch.utils.data.DataLoader(dataset['val'], batch_size=2048, shuffle=False, pin_memory=True),\n","}\n","\n","len(dataset['train']), len(dataset['val'])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(813965, 203417)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:46.472195Z","start_time":"2020-08-31T14:37:46.443197Z"},"id":"3Dx1vBgvw1Ho","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981725049,"user_tz":240,"elapsed":28,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"4f4696c5-ac08-43e4-8263-38eaceb80db5"},"source":["input, output = dataset['train'][10000]\n","print(tokenizer.seq_to_text(input))\n","print(output)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["buen parecer, de quien el un tiempo anduvo enamorado, aunque segun se entiende, ella jamas lo supo n\n","tensor(18)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:46.488195Z","start_time":"2020-08-31T14:37:46.473196Z"},"id":"GKRwaYw5w1Ho","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1623981725050,"user_tz":240,"elapsed":25,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"9ed054b1-ffed-431a-b08d-63ac440a359d"},"source":["tokenizer.seq_to_text([output])"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"iNOQiJ4vw1Ho"},"source":["## Embeddings"]},{"cell_type":"markdown","metadata":{"id":"JgSNQhryw1Hp"},"source":["Si bien hemos conseguido convertir nuestro texto a n√∫meros, una red neuronal seguir√° sin ser capaz de trabajar con nuestros datos ya que, como hemos visto en posts anteriores, √©stos tienen que estar normalizados. Adem√°s, en funci√≥n del `tokenizador` que utilicemos es posible que el  mismo car√°cter tenga asociados diferentes valores. Es por esto que necesitamos codificar nuestro texto de alguna manera. \n","\n","Una opci√≥n puede ser el `one-hot encoding`, al fin y al cabo podemos considerar cada letra como una categor√≠a y que nuestra red nos de a la salida una distribuci√≥n de probabilidad sobre todos los posibles car√°cteres. A continuaci√≥n tienes un ejemplo de este tipo de codificaci√≥n (utilizando palabras en vez de letras).\n","\n","![](https://i0.wp.com/shanelynnwebsite-mid9n9g1q9y8tt.netdna-ssl.com/wp-content/uploads/2018/01/one-hot-word-embedding-vectors.png?ssl=1)\n","\n","A nuestra red le daremos a la entrada un vector que representar√° cada elemento en el vocabulario. Este vector tendr√° una longitud igual al n√∫mero de elementos diferentes en el vocabulario, y estar√° lleno de ceros excepto por una posici√≥n (la posici√≥n que ocupe el elemento en concreto dentro del vocabulario, la lista de elementos √∫nicos). En nuestro caso podr√≠amos optar por esta alternativa, ya que apenas tenemos un centenar de car√°cteres diferentes. Sin embargo, cuando trabajemos con palabras, nuestros vocabularios ser√°n enormes (¬øcu√°ntas palabras hay en el diccionario?). Esto implica que trabajar con una codificaci√≥n `one-hot` ser√° muy costoso (vectores muy grandes) e ineficiente (pr√°cticamente llenos de ceros). Es por esto que utilizamos una mejor codificaci√≥n: los `embeddings`\n","\n","![](https://i.stack.imgur.com/5gAnY.png)\n","\n","Un embedding es una matriz con un n√∫mero de filas igual al tama√±o del vocabulario y un n√∫mero de columnas que nosotros decidiremos. Cada fila en la matriz representar√° la codificaci√≥n de una palabara (o car√°cter en nuestro ejemplo). A diferencia de la codificaci√≥n `one-hot`, estos vectores son densos (pueden tener valores diferentes de cero en cualquier posici√≥n). Adem√°s, estos valores son aprendidos por la red neuronal, de manera que podr√° representar los datos de la mejor forma posible para llevar a cabo la tarea. En la figura anterior tienes un ejemplo de un embedding entrenado, ¬øobservas alg√∫n patr√≥n?. Efectivamente, palabras similares tienen representaciones similares. Adem√°s, cada columna del embedding tiene un significado que permite establecer relaciones entre las diferentes representaciones."]},{"cell_type":"code","metadata":{"id":"WOdwi2v95Yy0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981725050,"user_tz":240,"elapsed":23,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"83b914e1-5422-45ef-e0e1-3eeafebaf562"},"source":["import numpy as np\n","\n","man = np.array([0, 0, 0])\n","woman = np.array([1, 0, 0])\n","boy = np.array([0, 1, 0])\n","girl = np.array([1, 1, 0])\n","prince = np.array([0, 1, 1])\n","princess = np.array([1, 1, 1])\n","queen = np.array([1, 0, 1])\n","king = np.array([0, 0, 1])\n","monarch = np.array([0.5, 0.5, 1])\n","\n","print((man - boy) + girl)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[1 0 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6cv9B2-Rw1Hq"},"source":["> ‚ö° ¬øQu√© resultado obtienes al restar el vector `boy` al vector `man` y sumarle el vector `girl`?"]},{"cell_type":"markdown","metadata":{"id":"mYGNGZXjw1Hq"},"source":["En `Pytorch` tenemos esta capa implementada en la clase `torch.nn.Embedding`, y m√°s adelante veremos como podemos utilizar `transfer learning` con embeddings pre-entrenados (lo cual nos dar√° una mejor representaci√≥n de nuestro vocabulario desde el principio sin tener que entrenar esta capa)."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:46.504195Z","start_time":"2020-08-31T14:37:46.489196Z"},"id":"3pdmYTIPw1Hq","executionInfo":{"status":"ok","timestamp":1623981725050,"user_tz":240,"elapsed":14,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}}},"source":["class CharRNN(torch.nn.Module):\n","  def __init__(self, input_size, embedding_size=128, hidden_size=256, num_layers=2, dropout=0.2):\n","    super().__init__()\n","    self.encoder = torch.nn.Embedding(input_size, embedding_size)\n","    self.rnn = torch.nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n","    self.fc = torch.nn.Linear(hidden_size, input_size)\n","\n","  def forward(self, x):\n","    x = self.encoder(x)\n","    x, h = self.rnn(x)         \n","    y = self.fc(x[:,-1,:])\n","    return y"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ZfdswkIw1Hq"},"source":["Nuestro modelo recibir√° *batches* de frases con el √≠ndice de cada palabra que nos proporciona el `tokenizador`. A la salida tendremos una distribuci√≥n de probabilidad sobre todos los posibles car√°cteres para cada frase del *batch*. Aquellos con mayor probabilidad ser√°n los que la red cree que son buenos candidatos para seguir la frase recibida a la entrada."]},{"cell_type":"code","metadata":{"id":"ZykPxakn9P1t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981725051,"user_tz":240,"elapsed":14,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"ae65c6df-99dd-426a-a482-dcf225a18f7a"},"source":["print(tokenizer.n_characters)\n","a = torch.randint(0, tokenizer.n_characters, (64, 50))\n","print(a)\n","print(a.shape)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["114\n","tensor([[110,  86,  72,  ..., 112, 104,  99],\n","        [ 98,  78,   5,  ...,  85,  56,  43],\n","        [ 42,  71, 107,  ...,  90,  89,  97],\n","        ...,\n","        [ 54, 102,  99,  ...,  13,  11,  93],\n","        [ 79,  14,  66,  ...,  50,  92,  41],\n","        [ 67,  56,  38,  ...,  56,  10, 101]])\n","torch.Size([64, 50])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:46.647195Z","start_time":"2020-08-31T14:37:46.505196Z"},"id":"LbJnw2JIw1Hr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981725942,"user_tz":240,"elapsed":903,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"6b389db8-0dfa-4d36-f095-2dfb41cd98db"},"source":["model = CharRNN(input_size=tokenizer.n_characters, embedding_size = 128)\n","outputs = model(torch.randint(0, tokenizer.n_characters, (64, 50)))\n","# outputs = model(a)\n","outputs.shape"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 114])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"XccCqQxjw1Hr"},"source":["## Entrenamiento"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T14:37:46.709195Z","start_time":"2020-08-31T14:37:46.649195Z"},"code_folding":[37],"id":"0_W4bsh7w1Hr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623981725942,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"6b048e87-8429-4766-ad1f-1dee53d8bc78"},"source":["from tqdm import tqdm\n","import numpy as np\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","\n","def fit(model, dataloader, epochs=10):\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        train_loss = []\n","        bar = tqdm(dataloader['train'])\n","        for batch in bar:\n","            X, y = batch\n","            X, y = X.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(X)\n","            loss = criterion(y_hat, y)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss.append(loss.item())\n","            bar.set_description(f\"loss {np.mean(train_loss):.5f}\")\n","        bar = tqdm(dataloader['val'])\n","        val_loss = []\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in bar:\n","                X, y = batch\n","                X, y = X.to(device), y.to(device)\n","                y_hat = model(X)\n","                loss = criterion(y_hat, y)\n","                val_loss.append(loss.item())\n","                bar.set_description(f\"val_loss {np.mean(val_loss):.5f}\")\n","        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f}\")\n","\n","def predict(model, X):\n","    model.eval() \n","    with torch.no_grad():\n","        X = torch.tensor(X).to(device)\n","        pred = model(X.unsqueeze(0))\n","        return pred"],"execution_count":21,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cZ8tEEbzBJj9","executionInfo":{"status":"ok","timestamp":1623981725943,"user_tz":240,"elapsed":6,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}}},"source":["# x = torch.tensor([1, 2, 3, 4])\n","# print(x.shape)\n","# print(torch.unsqueeze(x, 0))\n","# print(torch.unsqueeze(x, 0).shape)\n","# print(torch.unsqueeze(x, 1))\n","# print(torch.unsqueeze(x, 1).shape)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T15:43:20.416599Z","start_time":"2020-08-31T14:37:46.711195Z"},"id":"7-zy6ihgw1Hs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623984373256,"user_tz":240,"elapsed":2647319,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"46bcbe92-1126-4eed-8f8d-365350775fb0"},"source":["model = CharRNN(input_size=tokenizer.n_characters)\n","fit(model, dataloader, epochs=20)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["loss 1.85746: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:03<00:00, 12.86it/s]\n","val_loss 1.58761: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 11.05it/s]\n","loss 1.57818:   0%|          | 1/1590 [00:00<03:34,  7.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20 loss 1.85746 val_loss 1.58761\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.50182: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 12.99it/s]\n","val_loss 1.44527: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 11.01it/s]\n","loss 1.36547:   0%|          | 1/1590 [00:00<03:47,  6.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/20 loss 1.50182 val_loss 1.44527\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.39762: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:01<00:00, 13.04it/s]\n","val_loss 1.38782: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.44it/s]\n","loss 1.33189:   0%|          | 1/1590 [00:00<03:24,  7.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/20 loss 1.39762 val_loss 1.38782\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.34123: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:00<00:00, 13.20it/s]\n","val_loss 1.35171: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.38it/s]\n","loss 1.28169:   0%|          | 1/1590 [00:00<03:26,  7.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4/20 loss 1.34123 val_loss 1.35171\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.30351: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 13.00it/s]\n","val_loss 1.32247: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 10.98it/s]\n","loss 1.37470:   0%|          | 1/1590 [00:00<03:29,  7.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 5/20 loss 1.30351 val_loss 1.32247\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.27444: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 12.95it/s]\n","val_loss 1.30749: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 11.00it/s]\n","loss 1.30522:   0%|          | 1/1590 [00:00<03:31,  7.51it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 6/20 loss 1.27444 val_loss 1.30749\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.25246: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:03<00:00, 12.86it/s]\n","val_loss 1.28819: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.53it/s]\n","loss 1.26955:   0%|          | 1/1590 [00:00<03:24,  7.79it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 7/20 loss 1.25246 val_loss 1.28819\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.23344: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:01<00:00, 13.06it/s]\n","val_loss 1.27810: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.53it/s]\n","loss 1.19918:   0%|          | 1/1590 [00:00<03:41,  7.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 8/20 loss 1.23344 val_loss 1.27810\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.21751: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:00<00:00, 13.19it/s]\n","val_loss 1.27676: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.44it/s]\n","loss 1.20709:   0%|          | 1/1590 [00:00<03:25,  7.74it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 9/20 loss 1.21751 val_loss 1.27676\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.20392: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:01<00:00, 13.06it/s]\n","val_loss 1.26553: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:08<00:00, 11.20it/s]\n","loss 1.25531:   0%|          | 1/1590 [00:00<03:32,  7.49it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 10/20 loss 1.20392 val_loss 1.26553\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.19321: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:01<00:00, 13.05it/s]\n","val_loss 1.26109: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.44it/s]\n","loss 1.16651:   0%|          | 1/1590 [00:00<03:25,  7.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 11/20 loss 1.19321 val_loss 1.26109\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.18206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:01<00:00, 13.05it/s]\n","val_loss 1.25542: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 11.08it/s]\n","loss 1.13043:   0%|          | 1/1590 [00:00<03:17,  8.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 12/20 loss 1.18206 val_loss 1.25542\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.17158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 12.98it/s]\n","val_loss 1.25226: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.44it/s]\n","loss 1.11561:   0%|          | 1/1590 [00:00<03:35,  7.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 13/20 loss 1.17158 val_loss 1.25226\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.16307: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:03<00:00, 12.89it/s]\n","val_loss 1.25531: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:08<00:00, 11.17it/s]\n","loss 1.21215:   0%|          | 1/1590 [00:00<03:24,  7.75it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 14/20 loss 1.16307 val_loss 1.25531\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.15423: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:01<00:00, 13.08it/s]\n","val_loss 1.24867: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.54it/s]\n","loss 1.04365:   0%|          | 1/1590 [00:00<03:21,  7.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 15/20 loss 1.15423 val_loss 1.24867\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.14648: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 12.94it/s]\n","val_loss 1.24556: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 10.91it/s]\n","loss 1.09809:   0%|          | 1/1590 [00:00<03:20,  7.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 16/20 loss 1.14648 val_loss 1.24556\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.13989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 12.98it/s]\n","val_loss 1.24835: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.37it/s]\n","loss 1.15573:   0%|          | 1/1590 [00:00<03:35,  7.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 17/20 loss 1.13989 val_loss 1.24835\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.13372: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 12.98it/s]\n","val_loss 1.24238: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 10.91it/s]\n","loss 1.13923:   0%|          | 1/1590 [00:00<03:25,  7.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 18/20 loss 1.13372 val_loss 1.24238\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.12680: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 12.99it/s]\n","val_loss 1.24663: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:10<00:00,  9.49it/s]\n","loss 1.12582:   0%|          | 1/1590 [00:00<03:25,  7.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 19/20 loss 1.12680 val_loss 1.24663\n"],"name":"stdout"},{"output_type":"stream","text":["loss 1.12164: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1590/1590 [02:02<00:00, 12.98it/s]\n","val_loss 1.24455: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:09<00:00, 11.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch 20/20 loss 1.12164 val_loss 1.24455\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"taDlIiDlw1Hs"},"source":["## Generando texto"]},{"cell_type":"markdown","metadata":{"id":"rAHh732-w1Hs"},"source":["Una vez hemos entrenado nuestro modelo, podemos darle una frase para que genere la siguiente letra."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T15:43:20.431602Z","start_time":"2020-08-31T15:43:20.417599Z"},"id":"CL_lbakpw1Hs","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1623984373257,"user_tz":240,"elapsed":22,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"6443a690-0254-464d-c1ff-9cf506d304bd"},"source":["X_new = \"En un lugar de la mancha, \"\n","#X_new = \"Cuando en lo profundo de mi conciencia, \"\n","X_new_encoded = tokenizer.text_to_seq(X_new)\n","print(X_new_encoded)\n","y_pred = predict(model, X_new_encoded)\n","print(y_pred.shape)\n","y_pred = torch.argmax(y_pred, axis=1)[0].item()\n","tokenizer.seq_to_text([y_pred])"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[40, 23, 94, 30, 23, 94, 21, 30, 16, 10, 27, 94, 13, 14, 94, 21, 10, 94, 22, 10, 23, 12, 17, 10, 73, 94]\n","torch.Size([1, 114])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'y'"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"KZfCNXJMw1Ht"},"source":["Podemos generar m√°s letras a√±adiendo las predicciones como parte de la entrada, generando texto letra a letra."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T15:43:20.653601Z","start_time":"2020-08-31T15:43:20.433602Z"},"id":"chZN_kGXw1Ht","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1623984373788,"user_tz":240,"elapsed":538,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"046190a0-343d-485c-c192-305fc96c00c1"},"source":["for i in range(100):\n","  X_new_encoded = tokenizer.text_to_seq(X_new[-100:])\n","  y_pred = predict(model, X_new_encoded)\n","  y_pred = torch.argmax(y_pred, axis=1)[0].item()\n","  X_new += tokenizer.seq_to_text([y_pred])\n","\n","X_new"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'En un lugar de la mancha, y que es la mano a la mano a la mano a la mano a la mano a la mano a la mano a la mano a la mano a l'"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"AX9Oil1Nw1Ht"},"source":["C√≥mo puedes ver el text generado puede ser repetitivo si simplemente nos quedamos con la letra con mayor probabilidad. Para generar texto con mayor variedad, es com√∫n elegir de manera aleatoria una letra de entre las que tienen mayor probabilidad."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-31T15:59:01.326415Z","start_time":"2020-08-31T15:58:58.658570Z"},"id":"MRzXT5FBw1Ht","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623984376595,"user_tz":240,"elapsed":2811,"user":{"displayName":"Carlos Walter Pacheco Lora","photoUrl":"","userId":"05889892519883337793"}},"outputId":"76d6e0f4-8fc0-45ba-f41d-5082b8db4d1f"},"source":["temp=1\n","for i in range(1000):\n","  X_new_encoded = tokenizer.text_to_seq(X_new[-100:])\n","  y_pred = predict(model, X_new_encoded)\n","  y_pred = y_pred.view(-1).div(temp).exp()\n","  top_i = torch.multinomial(y_pred, 1)[0]\n","  predicted_char = tokenizer.all_characters[top_i]\n","  X_new += predicted_char\n","\n","print(X_new)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["En un lugar de la mancha, y que es la mano a la mano a la mano a la mano a la mano a la mano a la mano a la mano a la mano a la Zirera; y como le quitaje que habian recibido, se viendo en nuestros primeros, y el tan con ejercicio de poco manera, al cual sabia entro en todo; que es procura que no estaba bien, y luego no hay culpado del nombre vuestra gracia. Pues ¬øque piensa, dijo:\n","-Ahora oi querria que asi le hubiese, pues fue en mi mentiro un general de los bajes deste gahavilitado por el, hare tiempo que la tiene otra cosa que de hoy de simplado en todo el cuerto o amigo de bonco a buscarle de los hombres sin duda que en Espana. En\n","remotimiendo hasta la son animas, hacia mirando, tantas razones que fue que un sueltamente gustaron de las piedras. Creciome Sancho Panza, y ella ya el rocar en la sepultura y parecer a su pena, con la miranda y el fingido ni hecho se leyendo un hombrado, para conocimiento; mas decia a los pies padres, ni decir las aventuras que al tiempos y discursos pasiones, como demasio de muerto por el arabigo; y, con todo la misma librosa pena de la noche le habia visto en la lengua. Ella t\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M0nKCvCjw1Ht"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"JDIwagAlw1Hu"},"source":["En este post hemos aprendido c√≥mo implementar y entrenar una `red neuronal recurrente` para generar texto como si fuese Miguel de Cervantes. Para ello hemos utilizado su libro *Don Quijote de la Mancha* como dataset. En primer lugar, transformamos el texto en n√∫meros gracias al proceso de la `tokenizaci√≥n`. Despu√©s, codificamos cada car√°cter en el dataset utilizando una capa `embedding`, que permitir√° a la red neuronal encontrar la mejor representaci√≥n posible de los datos para llevar a cabo su tarea. Para generar texto, le pedimos a la red que nos de una distribuci√≥n de probabilidad sobre todos los posible car√°cteres a partir de una frase que le damos a la entrada. Utilizaremos esta distribuci√≥n para seleccionar un car√°cter que siga con la frase de manera convincente. Podemos repetir este proceso para generar secuencias m√°s largas."]}]}