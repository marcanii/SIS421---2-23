{"cells":[{"cell_type":"markdown","metadata":{"id":"Yg90deR13qYE"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/040_encoder_decoder/encoder_decoder.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"4Kzp2jHl3qY7"},"source":["# La arquitectura *Encoder-Decoder*"]},{"cell_type":"markdown","metadata":{"id":"pf2egeh0C_ER"},"source":["En posts anteriores hemos visto como podemos utilizar `redes neuronales recurrentes` para [generaci칩n de texto](https://sensioai.com/blog/037_charRNN) as칤 como [clasificaci칩n de texto](https://sensioai.com/blog/038_clasificacion_texto). En ambas aplicaciones hemos entrenado una red neuronal que alimentamos con una secuencia de texto, ya sean letras o palabras en una frase, a la cual le pedimos a la salida una distribuci칩n de probabilidad sobre la diferentes categor칤as (para el caso de la clasificaci칩n) o directamente el vocabulario (para la generaci칩n de texto). La principal limitaci칩n de estos modelos es que no podemos obtener m치s que una salida, y es por esto que en el caso de la generaci칩n de texto concatenamos la salida en cada instante a las entradas para utilizarlo de nuevo como entradas y obtener as칤 una nueva predicci칩n. En este post vamos a ver c칩mo podemos implementar modelos que no s칩lo sean capaces de recibir secuencias a la entrada, sino que tambi칠n puedan dar secuencias de longitud arbitraria a la salida. Este tipo de modelos se conocen como modelos *sequence to sequence* (o simplemente *seq2seq*) y pueden ser utilizados para tareas tales como la generaci칩n de texto, traducci칩n entre idiomas, resumir textos, etc.\n","\n","![](https://pytorch.org/tutorials/_images/seq2seq.png)"]},{"cell_type":"markdown","metadata":{"id":"bd8YnvbvC_ER"},"source":["> 游눠 Este post est치 basado en el siguiente [tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html), en el que podr치s encontrar m치s informaci칩n."]},{"cell_type":"markdown","metadata":{"id":"BtOkvrdIC_ES"},"source":["## El *dataset*"]},{"cell_type":"markdown","metadata":{"id":"zma1-yBoC_ES"},"source":["En este post vamos a ver c칩mo entrenar este tipo de arquitectura para traducir texto del ingl칠s al castellano. Puedes encontrar un ejemplo de dataset para traducci칩n [aqu칤](https://www.manythings.org/anki/). Una vez descargados los datos vamos a leer el archivo, separando los pares de frases de cada ejemplo."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2378,"status":"ok","timestamp":1686932132675,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"CtzDFtguEHMK","outputId":"3953708b-081c-4867-8ecc-068ec673446e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1686932132676,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Rd6sDB6RC_ET"},"outputs":[],"source":["import unicodedata\n","import re\n","\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s\n","\n","def read_file(file, reverse=False):\n","    # Read the file and split into lines\n","    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n","\n","    return pairs"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7261,"status":"ok","timestamp":1686932139934,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"6RinX_1uC_EU"},"outputs":[],"source":["pairs = read_file('/content/drive/MyDrive/Colab Notebooks/deep_learning/18 nlp/04 traduccion/spa.txt')\n","\n","# pairs = read_file('spa.txt')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1686932139934,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"uHjkl39BC_EV","outputId":"64450a75-54d3-49de-c0fe-b33b3f457935"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['he was reading a newspaper .', 'el estaba leyendo el periodico .']"]},"metadata":{},"execution_count":4}],"source":["import random\n","\n","random.choice(pairs)"]},{"cell_type":"markdown","metadata":{"id":"IxhmrK8tC_EW"},"source":["Como ya hemos visto en los posts anteriores, necesitamos un `tokenizer`. En este caso, la clase `Lang` se encargar치 de asignar un 칤ndice 칰nico a cada palabra calculando tambi칠n su frecuencia para, m치s tarde, poder quedarnos s칩lo con las palabras m치s frecuentes. Necesitaremos, adem치s, dos nuevos *tokens* especiales: el token `<eos>` y el token `<sos>` para indicar, respectivamente, el inicio y final de una frase. M치s adelante veremos c칩mo utilizarlos."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686932139935,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"OhvIdvs0C_EX"},"outputs":[],"source":["SOS_token = 0\n","EOS_token = 1\n","PAD_token = 2\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\"}\n","        self.n_words = 3  # Count SOS, EOS and PAD\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    def indexesFromSentence(self, sentence):\n","        return [self.word2index[word] for word in sentence.split(' ')]\n","\n","    def sentenceFromIndex(self, index):\n","        return [self.index2word[ix] for ix in index]"]},{"cell_type":"markdown","metadata":{"id":"YefvAE19C_EX"},"source":["Opcionalmente, tambi칠n podemos indicar la longitud m치xima de las frases a utilizar as칤 como un conjunto de comienzos de frases que queramos filtrar. Esto lo hacemos 칰nicamente para acelerar el proceso de entrenamiento, trabajando con un conjunto peque침o de datos."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686932139935,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"moCeuAwPC_EY"},"outputs":[],"source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s \",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","\n","def filterPair(p, lang, filters, max_length):\n","    return len(p[0].split(' ')) < max_length and \\\n","        len(p[1].split(' ')) < max_length and \\\n","        p[lang].startswith(filters)\n","\n","def filterPairs(pairs, filters, max_length, lang=0):\n","    return [pair for pair in pairs if filterPair(pair, lang, filters, max_length)]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6723,"status":"ok","timestamp":1686932146655,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"g90yDZq9C_EY","outputId":"704dafe4-0744-4cbe-b628-3cc4dd27945f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tenemos 134142 pares de frases\n","Longitud vocabularios:\n","spa 13552\n","eng 26182\n"]},{"output_type":"execute_result","data":{"text/plain":["['a promise is a promise . EOS', 'una promesa es una promesa . EOS']"]},"metadata":{},"execution_count":7}],"source":["def prepareData(file, filters=None, max_length=None, reverse=False):\n","\n","    pairs = read_file(file, reverse)\n","    print(f\"Tenemos {len(pairs)} pares de frases\")\n","\n","    if filters is not None:\n","        assert max_length is not None\n","        pairs = filterPairs(pairs, filters, max_length, int(reverse))\n","        print(f\"Filtramos a {len(pairs)} pares de frases\")\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang('eng')\n","        output_lang = Lang('spa')\n","    else:\n","        input_lang = Lang('spa')\n","        output_lang = Lang('eng')\n","\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","\n","        # add <eos> token\n","        pair[0] += \" EOS\"\n","        pair[1] += \" EOS\"\n","\n","    print(\"Longitud vocabularios:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","\n","    return input_lang, output_lang, pairs\n","\n","input_lang, output_lang, pairs = prepareData('/content/drive/MyDrive/Colab Notebooks/deep_learning/18 nlp/04 traduccion/spa.txt')\n","\n","# descomentar para usar el dataset filtrado\n","#input_lang, output_lang, pairs = prepareData('spa.txt', filters=eng_prefixes, max_length=MAX_LENGTH)\n","\n","random.choice(pairs)"]},{"cell_type":"markdown","metadata":{"id":"uF8Zow3nC_EY"},"source":["Una vez construidos los dos vocabularios, podemos obtener los 칤ndices a partir de una frase, y viceversa, de la siguiente manera."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1686932146656,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"IXWGi2GkC_EZ","outputId":"cfbc2abb-628f-4803-c075-09ad8e6c31f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[72, 5394, 143, 4]"]},"metadata":{},"execution_count":8}],"source":["output_lang.indexesFromSentence('tengo mucha sed .')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1686932146656,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"5P2QM37dC_EZ","outputId":"7fbd4a11-75d0-478d-bf5e-f94fc63fba70"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['tengo', 'mucha', 'sed', '.']"]},"metadata":{},"execution_count":9}],"source":["output_lang.sentenceFromIndex([72, 5394, 143, 4])"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686932146656,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"XvxZM994yBhc"},"outputs":[],"source":["# input_lang.sentenceFromIndex([72, 5394, 143, 4])\n","# input_lang.indexesFromSentence('i have much money .')"]},{"cell_type":"markdown","metadata":{"id":"cFmdmdQpC_EZ"},"source":["Para terminar, las siguientes clases se encargar치n de alimentar nuestro modelo *seq2seq* utilizando las clases `Dataset` y `DataLoader` de `Pytorch`. Debido a que nuestras frases pueden tener diferentes longitudes, tenemos que asegurarnos que al construir nuestros batches todas tengan la misma longitud, ya que para alimentar la red necesitamos tensores rectangulares. Esto lo conseguimos con la funci칩n `collate`."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1342,"status":"ok","timestamp":1686932147995,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"qHqk7a_jC_EZ","outputId":"2cb54697-a64e-43ed-b55e-5ae9eba2182e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(107313, 26829)"]},"metadata":{},"execution_count":11}],"source":["import torch\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, input_lang, output_lang, pairs):\n","        self.input_lang = input_lang\n","        self.output_lang = output_lang\n","        self.pairs = pairs\n","\n","    def __len__(self):\n","        return len(self.pairs)\n","\n","    def __getitem__(self, ix):\n","        return torch.tensor(self.input_lang.indexesFromSentence(self.pairs[ix][0]), device=device, dtype=torch.long), \\\n","               torch.tensor(self.output_lang.indexesFromSentence(self.pairs[ix][1]), device=device, dtype=torch.long)\n","\n","    def collate(self, batch):\n","        # calcular longitud m치xima en el batch\n","        max_input_len, max_output_len = 0, 0\n","        for input_sentence, output_sentence in batch:\n","            max_input_len = len(input_sentence) if len(input_sentence) > max_input_len else max_input_len\n","            max_output_len = len(output_sentence) if len(output_sentence) > max_output_len else max_output_len\n","        # a침adimos padding a las frases cortas para que todas tengan la misma longitud\n","        input_sentences, output_sentences = [], []\n","        for input_sentence, output_sentence in batch:\n","            input_sentences.append(torch.nn.functional.pad(input_sentence, (0, max_input_len - len(input_sentence)), 'constant', self.input_lang.word2index['PAD']))\n","            output_sentences.append(torch.nn.functional.pad(output_sentence, (0, max_output_len - len(output_sentence)), 'constant', self.output_lang.word2index['PAD']))\n","        # opcionalmente, podr칤amos re-ordenar las frases en el batch (algunos modelos lo requieren)\n","        return torch.stack(input_sentences), torch.stack(output_sentences)\n","\n","# separamos datos en train-test\n","train_size = len(pairs) * 80 // 100\n","train = pairs[:train_size]\n","test = pairs[train_size:]\n","\n","dataset = {\n","    'train': Dataset(input_lang, output_lang, train),\n","    'test': Dataset(input_lang, output_lang, test)\n","}\n","\n","len(dataset['train']), len(dataset['test'])"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1793,"status":"ok","timestamp":1686932149785,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"RDktEuzUC_Ea","outputId":"21f9c696-6b64-45ba-cee4-eb5d3ec90abc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([3, 4, 1], device='cuda:0'), tensor([5, 4, 1], device='cuda:0'))"]},"metadata":{},"execution_count":12}],"source":["input_sentence, output_sentence = dataset['train'][1]\n","\n","input_sentence, output_sentence"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1686932149786,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"cBI5YUupC_Ea","outputId":"b668c85b-fe67-48ee-f0c0-b8ad87a3bad1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['go', '.', 'EOS'], ['vete', '.', 'EOS'])"]},"metadata":{},"execution_count":13}],"source":["input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1686932149787,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"J58o8kWVC_Ea","outputId":"e766b45c-ef93-4c53-9fce-c81669a5a61a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([64, 12]), torch.Size([64, 12]))"]},"metadata":{},"execution_count":14}],"source":["dataloader = {\n","    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True, collate_fn=dataset['train'].collate),\n","    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False, collate_fn=dataset['test'].collate),\n","}\n","\n","inputs, outputs = next(iter(dataloader['train']))\n","inputs.shape, outputs.shape"]},{"cell_type":"markdown","metadata":{"id":"ofqSU7vVC_Eb"},"source":["## El modelo"]},{"cell_type":"markdown","metadata":{"id":"1PHHx68cC_Eb"},"source":["Una vez tenemos nuestros *dataloaders* listos, vamos a ver c칩mo construir nuestro modelo siguiendo la arquitectura `encoder-decoder`."]},{"cell_type":"markdown","metadata":{"id":"WXV1uwhtC_Eb"},"source":["### El *encoder*"]},{"cell_type":"markdown","metadata":{"id":"RXTvNW4OC_Eb"},"source":["Como `encoder` utilizaremos una `red neuronal recurrente` como las que ya hemos utilizado en los posts anteriores. Tendremos una primera capa `embedding` que se encargar치 de proveer a la `RNN` de la representaci칩n vectorial de cada palabra y luego la capa `RNN` (que puede ser tambi칠n una `LSTM` o `GRU` como ya vimos en este [post](https://sensioai.com/blog/036_rnn_mejoras)). El `encoder` codificar치 la frase original y nos quedaremos con las salidas de las capas ocultas en el 칰ltimo paso (cuando ya ha visto toda la frase). Este tensor ser치 el responsable de codificar el significado de la frase para que luego el `decoder` pueda traducirla."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1686932149787,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"vDUmpIaRC_Eb"},"outputs":[],"source":["class Encoder(torch.nn.Module):\n","    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n","        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n","\n","    def forward(self, input_sentences):\n","        embedded = self.embedding(input_sentences)\n","        output, hidden = self.gru(embedded)\n","        # del encoder nos interesa el 칰ltimo *hidden state*\n","        return hidden"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1686932149787,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"uTQt4rvoC_Ec","outputId":"5bf460e1-cbb8-4574-c1bd-bebc5c9dea2b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 64, 100])"]},"metadata":{},"execution_count":16}],"source":["encoder = Encoder(input_size=input_lang.n_words)\n","hidden = encoder(torch.randint(0, input_lang.n_words, (64, 10)))\n","\n","# [num layers, batch size, hidden size]\n","hidden.shape"]},{"cell_type":"markdown","metadata":{"id":"adyZHlBFC_Ec"},"source":["### El *decoder*"]},{"cell_type":"markdown","metadata":{"id":"V8RFpDSaC_Ec"},"source":["El `decoder` ser치 de nuevo una `red neuronal recurrente`. A diferencia del `encoder`, el estado oculto del `decoder` lo inicializaremos con el tensor obtenido a la salida del `encoder`. Tanto durante el entrenamiento como en fase de inferencia, le daremos al decoder como primera palabra el token `<sos>`. Con esta informaci칩n, y el estado oculto del `encoder`, deber치 predecir la primera palabra de la frase traducida. Seguidamente, usaremos esta primera palabra como nueva entrada junto al estado oculto obtenido en el paso anterior para generar la segunda palabra. Repetiremos este proceso hasta que el `decoder` nos de el token `<eos>`, indicando que la frase ha terminado."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1686932149788,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"_yvRG2kXC_Ec"},"outputs":[],"source":["class Decoder(torch.nn.Module):\n","    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2):\n","        super().__init__()\n","        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n","        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n","        self.out = torch.nn.Linear(hidden_size, input_size)\n","\n","    def forward(self, input_words, hidden):\n","        embedded = self.embedding(input_words)\n","        output, hidden = self.gru(embedded, hidden)\n","        output = self.out(output.squeeze(1))\n","        return output, hidden"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1686932149788,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Fcz74tqPC_Ec","outputId":"c3e36a6a-70b4-42d0-eb8d-ff0e3771b8d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 26182])"]},"metadata":{},"execution_count":18}],"source":["decoder = Decoder(input_size=output_lang.n_words)\n","output, decoder_hidden = decoder(torch.randint(0, output_lang.n_words, (64, 1)), hidden)\n","\n","# [batch size, vocab size]\n","output.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1686932149788,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"zIZ-DHMrC_Ed","outputId":"79d7cc02-0bea-4c1f-f556-8d6016ebec59"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 64, 100])"]},"metadata":{},"execution_count":19}],"source":["# [num layers, batch size, hidden size]\n","decoder_hidden.shape"]},{"cell_type":"markdown","metadata":{"id":"Pdnf3JvXC_Ed"},"source":["## Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"OOdgZQUCC_Ed"},"source":["Vamos a implementar el bucle de entrenamiento. En primer lugar, al tener ahora dos redes neuronales, necesitaremos dos optimizadores (uno para el `encoder` y otro para el `decoder`). Al `encoder` le pasaremos la frase en el idioma original, y obtendremos el estado oculto final. Este estado oculto lo usaremos para inicializar el `decoder` que, junto al token `<sos>`, generar치 la primera palabra de la frase traducida. Repetiremos el proceso, utilizando como entrada la anterior salida del decoder, hasta obtener el token `<eos>`."]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1686932149789,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"m_G7AD-hC_Ed"},"outputs":[],"source":["from tqdm import tqdm\n","import numpy as np\n","\n","def fit(encoder, decoder, dataloader, epochs=10):\n","    encoder.to(device)\n","    decoder.to(device)\n","    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n","    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    for epoch in range(1, epochs+1):\n","        encoder.train()\n","        decoder.train()\n","        train_loss = []\n","        bar = tqdm(dataloader['train'])\n","        for batch in bar:\n","            input_sentences, output_sentences = batch\n","            bs = input_sentences.shape[0]\n","            loss = 0\n","            encoder_optimizer.zero_grad()\n","            decoder_optimizer.zero_grad()\n","            # obtenemos el 칰ltimo estado oculto del encoder\n","            hidden = encoder(input_sentences)\n","            # calculamos las salidas del decoder de manera recurrente\n","            decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n","            for i in range(output_sentences.shape[1]):\n","                output, hidden = decoder(decoder_input, hidden)\n","                loss += criterion(output, output_sentences[:, i].view(bs))\n","                # el siguiente input ser치 la palbra predicha\n","                decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n","            # optimizaci칩n\n","            loss.backward()\n","            encoder_optimizer.step()\n","            decoder_optimizer.step()\n","            train_loss.append(loss.item())\n","            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n","\n","        val_loss = []\n","        encoder.eval()\n","        decoder.eval()\n","        with torch.no_grad():\n","            bar = tqdm(dataloader['test'])\n","            for batch in bar:\n","                input_sentences, output_sentences = batch\n","                bs = input_sentences.shape[0]\n","                loss = 0\n","                # obtenemos el 칰ltimo estado oculto del encoder\n","                hidden = encoder(input_sentences)\n","                # calculamos las salidas del decoder de manera recurrente\n","                decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n","                for i in range(output_sentences.shape[1]):\n","                    output, hidden = decoder(decoder_input, hidden)\n","                    loss += criterion(output, output_sentences[:, i].view(bs))\n","                    # el siguiente input ser치 la palbra predicha\n","                    decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n","                val_loss.append(loss.item())\n","                bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_1N3aHWC_Ed","executionInfo":{"status":"ok","timestamp":1686933867595,"user_tz":240,"elapsed":1717814,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"c39c593f-b625-49bc-a8cc-26fe70bc1565"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/30 loss 37.69305: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:52<00:00, 31.95it/s]\n","Epoch 1/30 val_loss 72.26421: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.47it/s]\n","Epoch 2/30 loss 29.95790: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.75it/s]\n","Epoch 2/30 val_loss 68.42555: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 17.50it/s]\n","Epoch 3/30 loss 26.55357: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:50<00:00, 33.12it/s]\n","Epoch 3/30 val_loss 66.44819: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 16.67it/s]\n","Epoch 4/30 loss 24.14408: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:50<00:00, 33.05it/s]\n","Epoch 4/30 val_loss 65.05403: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 17.46it/s]\n","Epoch 5/30 loss 22.24489: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:52<00:00, 32.06it/s]\n","Epoch 5/30 val_loss 63.24605: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.04it/s]\n","Epoch 6/30 loss 20.72656: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:50<00:00, 33.09it/s]\n","Epoch 6/30 val_loss 62.79085: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.75it/s]\n","Epoch 7/30 loss 19.46702: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:50<00:00, 32.88it/s]\n","Epoch 7/30 val_loss 62.32363: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.68it/s]\n","Epoch 8/30 loss 18.42703: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.71it/s]\n","Epoch 8/30 val_loss 62.56858: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.92it/s]\n","Epoch 9/30 loss 17.51321: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:52<00:00, 32.24it/s]\n","Epoch 9/30 val_loss 63.32541: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 17.21it/s]\n","Epoch 10/30 loss 16.72969: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:50<00:00, 32.92it/s]\n","Epoch 10/30 val_loss 62.95714: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 16.89it/s]\n","Epoch 11/30 loss 16.03750: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.43it/s]\n","Epoch 11/30 val_loss 63.57241: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 17.90it/s]\n","Epoch 12/30 loss 15.43148: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:52<00:00, 31.70it/s]\n","Epoch 12/30 val_loss 63.75719: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 16.11it/s]\n","Epoch 13/30 loss 14.90028: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.31it/s]\n","Epoch 13/30 val_loss 64.10619: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.34it/s]\n","Epoch 14/30 loss 14.41978: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:50<00:00, 33.08it/s]\n","Epoch 14/30 val_loss 64.22167: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 17.30it/s]\n","Epoch 15/30 loss 13.98723: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:50<00:00, 33.22it/s]\n","Epoch 15/30 val_loss 65.69188: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 16.96it/s]\n","Epoch 16/30 loss 13.57970: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.60it/s]\n","Epoch 16/30 val_loss 65.17625: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 17.99it/s]\n","Epoch 17/30 loss 13.22510: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.87it/s]\n","Epoch 17/30 val_loss 65.92206: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.98it/s]\n","Epoch 18/30 loss 12.89830: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.73it/s]\n","Epoch 18/30 val_loss 65.75103: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.88it/s]\n","Epoch 19/30 loss 12.60229: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.79it/s]\n","Epoch 19/30 val_loss 66.52507: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.94it/s]\n","Epoch 20/30 loss 12.32152: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.72it/s]\n","Epoch 20/30 val_loss 66.92089: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 17.95it/s]\n","Epoch 21/30 loss 12.07422: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.55it/s]\n","Epoch 21/30 val_loss 67.38679: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 16.87it/s]\n","Epoch 22/30 loss 11.83905: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.38it/s]\n","Epoch 22/30 val_loss 69.07489: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 17.46it/s]\n","Epoch 23/30 loss 11.60147: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.60it/s]\n","Epoch 23/30 val_loss 68.16777: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.98it/s]\n","Epoch 24/30 loss 11.41286: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.65it/s]\n","Epoch 24/30 val_loss 70.03828: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.99it/s]\n","Epoch 25/30 loss 11.20855: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.78it/s]\n","Epoch 25/30 val_loss 69.72863: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.46it/s]\n","Epoch 26/30 loss 11.04012: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:50<00:00, 32.90it/s]\n","Epoch 26/30 val_loss 70.36337: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 17.49it/s]\n","Epoch 27/30 loss 10.87234: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.78it/s]\n","Epoch 27/30 val_loss 71.05075: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:06<00:00, 16.97it/s]\n","Epoch 28/30 loss 10.71271: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.81it/s]\n","Epoch 28/30 val_loss 70.69996: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 17.71it/s]\n","Epoch 29/30 loss 10.54739: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.30it/s]\n","Epoch 29/30 val_loss 71.76396: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 18.84it/s]\n","Epoch 30/30 loss 10.41257: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 1677/1677 [00:51<00:00, 32.67it/s]\n","Epoch 30/30 val_loss 72.83676: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 105/105 [00:05<00:00, 19.07it/s]\n"]}],"source":["fit(encoder, decoder, dataloader, epochs=30)"]},{"cell_type":"markdown","metadata":{"id":"LjwZ8FCYC_Ee"},"source":["Como puedes ver, la *loss* de enterenamiento baja indicando que nuestra red est치 aprendiendo a traducir. Sin embargo, la *loss* de validaci칩n sube indicando que estamos haciendo *overfitting*. Esto es normal ya que estamos utilizando muy pocos datos para el entrenamiento, para reducir este problema tendr칤as que utilizar un dataset con m치s ejemplos."]},{"cell_type":"markdown","metadata":{"id":"1EIOmMltC_Ee"},"source":["## Generando traducciones"]},{"cell_type":"markdown","metadata":{"id":"tpa_oOF5C_Ee"},"source":["Una vez tenemos nuestro modelo entrenado, podemos utilizarlo para traducir frases del ingl칠s al castellano de la siguiente manera."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"BDq4Y7xSC_Ee","outputId":"dab9222e-5ee8-4ab5-d6d8-dae8dfa24feb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686933867596,"user_tz":240,"elapsed":17,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['be', 'good', '.', 'EOS'], ['sea', 'bueno', '.', 'EOS'])"]},"metadata":{},"execution_count":22}],"source":["input_sentence, output_sentence = dataset['train'][129]\n","input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"9fRLwXsFC_Ee","executionInfo":{"status":"ok","timestamp":1686933867596,"user_tz":240,"elapsed":6,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[],"source":["def predict(input_sentence):\n","    # obtenemos el 칰ltimo estado oculto del encoder\n","    hidden = encoder(input_sentence.unsqueeze(0))\n","    # calculamos las salidas del decoder de manera recurrente\n","    decoder_input = torch.tensor([[output_lang.word2index['SOS']]], device=device)\n","    # iteramos hasta que el decoder nos de el token <eos>\n","    outputs = []\n","    while True:\n","        output, hidden = decoder(decoder_input, hidden)\n","        decoder_input = torch.argmax(output, axis=1).view(1, 1)\n","        outputs.append(decoder_input.cpu().item())\n","        if decoder_input.item() == output_lang.word2index['EOS']:\n","            break\n","    return output_lang.sentenceFromIndex(outputs)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"9KgVQxVbC_Ee","outputId":"61a54fa9-49fd-43ca-c685-54bf2f193236","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686933867596,"user_tz":240,"elapsed":5,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['sean', 'buenas', '.', 'EOS']"]},"metadata":{},"execution_count":24}],"source":["predict(input_sentence)"]},{"cell_type":"markdown","metadata":{"id":"I1eswXQpC_Ee"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"pV8i91ayC_Ef"},"source":["En este post hemos aprendido a implementar una arquitectura `encoder-decoder` que nos permite trabajar con secuencia de longitud arbitraria tanto en las entradas como en las salida. El ejemplo de aplicaci칩n que hemos llevado a cabo es la traducci칩n de texto. Esta arquitectura es muy vers치til y puede utilizarse, con peque침os cambios, para otras aplicaciones como generaci칩n de descripciones a partir de im치genes (cambiando el encoder por una red convolucional, por ejemplo). Si bien esta arquitectura nos permite obtener buenos resultados, se ve limitada en el caso en el que trabajemos con secuencias muy largas, ya que el 칰ltimo estado del `encoder` es responsable de codificar todo el significado de la frase original, lo cual puede ser dif칤cil. Podemos mejorar esta arquitectura a침adiendo una capa de `atenttion` en el `decoder`, el cual no solo recibir치 este estado oculto del `encoder` si no que adem치s ser치 capaz de mirar a todas las salidas del mismo para decidir, en cada caso, la mejor palabra a traducir. En el pr칩ximo post veremos como implementar este nuevo mecanismo."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/040_encoder_decoder/encoder_decoder.ipynb","timestamp":1638514035330}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}