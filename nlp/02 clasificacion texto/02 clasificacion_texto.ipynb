{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/038_clasificacion_texto/clasificacion_texto.ipynb","timestamp":1638513082111}]},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"RXzEehEz_TBZ"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/038_clasificacion_texto/clasificacion_texto.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"w-1V4Yub_TBd"},"source":["# Clasificaci√≥n de texto"]},{"cell_type":"markdown","metadata":{"id":"CuDVXm0l_TBe"},"source":["En el [post](https://sensioai.com/blog/037_charRNN) anterior aprendimos a c√≥mo podemos entrenar una `red neuronal recurrente` para generar texto letra a letra, una tarea muy interesante dentro del mundo del `procesado de lenguaje natur` o `NLP` (*natural language processing*) por sus siglas en ingl√©s. A√∫n as√≠, posiblemente la tarea m√°s interesante desde un punto de vista pr√°ctico y con m√°s aplicaciones en la industria sea la de `clasificaci√≥n de texto`. De la misma manera que podemos entrenar `redes neuronales` para [clasificaci√≥n de im√°genes](https://sensioai.com/blog/033_receta_entrenamiento), es posible entrenar modelos de `machine learning` capaces de asignar una etiqueta determinada a un trozo de texto. Podemos encontrar este tipo de aplicaciones en redes sociales, por ejemplo, para detectar autom√°ticamente mensaje ofensivos o en opiniones de usuarios sobre art√≠culos para medir su satisfacci√≥n. En este post vamos a ver c√≥mo podemos entrenar una `red neuronal recurrente` para clasificar *reviews* de pel√≠culas, una tarea tambi√©n conocida por el nombre de `sentiment analysis`."]},{"cell_type":"markdown","metadata":{"id":"Lw0ClKKg_TBe"},"source":[" ## El *dataset*"]},{"cell_type":"markdown","metadata":{"id":"Tq7osnGA_TBf"},"source":["En el post anterior descargamos el libro *Don Quijote de la Mancha* en formato *txt*, luego lo cargamos en `Python` para proceder al proceso de `tokenizaci√≥n`. Si bien implementamos nuestra propia l√≥gica de procesado de texto, a la pr√°ctica es m√°s conveniente utilizar herramientas de terceros bien testeadas y optimizadas. Entre las diferentes librer√≠as que existen de `NLP`, nosotros utilizaremos [torchtext](https://pytorch.org/text/) ya que est√° bien integrada con el ecosistema de `Pytorch`."]},{"cell_type":"code","source":["!pip install torchtext\n","# !pip install torchtext==0.1.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9A9hLQB34wvp","executionInfo":{"status":"ok","timestamp":1686885924574,"user_tz":240,"elapsed":3882,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"outputId":"4c6c0f53-89e9-417c-8847-6de9f166cb72"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.27.1)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.22.4)\n","Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (1.26.15)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (16.0.5)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"]}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:39:11.207060Z","start_time":"2020-09-01T16:39:10.641059Z"},"id":"qA6gL41Y_TBf","executionInfo":{"status":"ok","timestamp":1686886521077,"user_tz":240,"elapsed":403,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"3448e530-946a-40b7-d4b4-b5073cc76a52"},"source":["import torch\n","import torchtext\n","from torchtext import data\n","from torchtext import datasets\n","\n","torchtext.__version__"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0.15.2+cpu'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"BuAdEs4b_TBg"},"source":["En `torchtext` tenemos disponible multitud de datasets que podemos utilizar, los cuales son ideales cuando estamos aprendiendo a trabajar con `redes neuronales` para tareas de `NLP`. En este caso descargaremos el dataset `IMDB` que contiene opiniones sobre pel√≠culas. Nuestro objetivo ser√°, dada una de estas *reviews* asignarle una etiqueta binaria (opini√≥n positiva o negativa)."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.615532Z","start_time":"2020-09-01T16:39:11.208061Z"},"id":"Fp09lmp-_TBh","outputId":"dfcad071-bb75-43cd-c0f9-a5809bd33786","colab":{"base_uri":"https://localhost:8080/","height":218},"executionInfo":{"status":"error","timestamp":1686886564760,"user_tz":240,"elapsed":353,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["TEXT = data.Field(tokenize = 'spacy')\n","LABEL = data.LabelField(dtype = torch.long)\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"],"execution_count":9,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-72faf5018373>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTEXT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'spacy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLABEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMDB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'torchtext.data' has no attribute 'Field'"]}]},{"cell_type":"markdown","metadata":{"id":"YhMUqm3f_TBi"},"source":["> ‚ö° La clase `torchtext.data.Field` contiene toda la l√≥gica de tokenizaci√≥n y procesado de texto necesaria, lo cual nos facilitar√° mucho la vida para esta tarea. Puedes aprender m√°s sobre esta clase, y la librer√≠a en general, en su [documentaci√≥n](https://pytorch.org/text/data.html)."]},{"cell_type":"markdown","metadata":{"id":"WlsqjtPb_TBj"},"source":["En este caso en concreto, disponemos de 25000 muestras tanto para el entrenamiento como evaluaci√≥n de nuestros modelos."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.632530Z","start_time":"2020-09-01T16:40:09.616535Z"},"id":"GQVUALsu_TBj","executionInfo":{"status":"aborted","timestamp":1686885887057,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["len(train_data), len(test_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CmUOMFaa_TBj"},"source":["De la siguiente manera podemos ver un ejemplo de muestra de nuestro dataset, que est√° compuesto por el texto y la valoraci√≥n."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.647529Z","start_time":"2020-09-01T16:40:09.633530Z"},"id":"x9APvEWp_TBk","executionInfo":{"status":"aborted","timestamp":1686885887057,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["print(vars(train_data.examples[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jNhALD16_TBk"},"source":["### Tokenizaci√≥n"]},{"cell_type":"markdown","metadata":{"id":"ELW0P8im_TBk"},"source":["Adem√°s de proveernos con varios datasets, `torchtext` tambi√©n nos facilita mucho la vida a la hora de llevar a cabo el proceso de `tokenizaci√≥n`. En este caso vamos a construir un vocabulario que contendr√° un n√∫mero determinado de palabras (ya que si aqueremos incluirlas los requisitos computacionales se disparar√≠an). Para ello el tokenizador calcular√° la frecuencia de cada palabra en el texto y se quedar√° con la cantidad que especifiquemos."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.841436Z","start_time":"2020-09-01T16:40:09.648529Z"},"id":"49J2Ra3n_TBl","executionInfo":{"status":"aborted","timestamp":1686885887058,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["MAX_VOCAB_SIZE = 10000\n","\n","TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n","LABEL.build_vocab(train_data)\n","\n","len(TEXT.vocab), len(LABEL.vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-atp2OMO_TBl"},"source":["Como puedes ver tenemos un vocabulario con la longitud determinada m√°s dos, estos dos *tokens* extra corresponden a los *tokens* `<unk>`, que se le asignar√°n a las palabras desconocidas y las menos frecuentes que no hayan pasado el primer filtro, y el *token* `<pad>`, que se usar√° para que todas las frases en un *batch* tengan la misma longitud (necesitamos tensores recutangulares para entrenar nuestra red)."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.883957Z","start_time":"2020-09-01T16:40:10.843442Z"},"id":"gRPWqhBh_TBl","executionInfo":{"status":"aborted","timestamp":1686885887058,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["TEXT.vocab.freqs.most_common(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.899961Z","start_time":"2020-09-01T16:40:10.885959Z"},"id":"tWaGfhpI_TBm","executionInfo":{"status":"aborted","timestamp":1686885887058,"user_tz":240,"elapsed":10,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["TEXT.vocab.itos[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.915962Z","start_time":"2020-09-01T16:40:10.900958Z"},"id":"J2k2jhPw_TBm","executionInfo":{"status":"aborted","timestamp":1686885887059,"user_tz":240,"elapsed":11,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["LABEL.vocab.stoi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nBrp0SUJ_TBm"},"source":["El √∫ltimo paso para tener nuestros datos listos para entrenar una red neuronal es construir el `DataLoader` encargado de alimentar nuestra red con *batches* de frases de manera eficiente. Para ello utilizamos la clase `torchtext.data.BucketIterator`, que adem√°s juntar√° frases de similar longitud minimazndo el *padding* necesario."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.947957Z","start_time":"2020-09-01T16:40:10.916958Z"},"id":"Z_iiEEql_TBm","executionInfo":{"status":"aborted","timestamp":1686885887060,"user_tz":240,"elapsed":12,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","dataloader = {\n","    'train': data.BucketIterator(train_data, batch_size=64, shuffle=True, sort_within_batch=True, device=device),\n","    'test': data.BucketIterator(test_data, batch_size=64, device=device)\n","}\n","\n","print(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0EBjUWzK_TBn"},"source":["## El modelo"]},{"cell_type":"markdown","metadata":{"id":"m47DBdTv_TBn"},"source":["Para poder clasificar texto utilizaremos una [red recurrente](https://sensioai.com/blog/034_rnn_intro) de tipo `many-to-one`, la cual recibir√° el texto palabra por palabra. Usaremos el √∫ltimo estado oculto (el cual contendr√° informaci√≥n de toda la frase) para generar nuestra predicci√≥n final. Cada palabra estar√° representada por un vector, el cual ser√° aprendido por la red en la capa `embedding` (puedes aprender m√°s sobre esta capa en nuestro [post](https://sensioai.com/blog/037_charRNN) anterior)."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.963957Z","start_time":"2020-09-01T16:40:10.948957Z"},"id":"6pMYlfZN_TBn","executionInfo":{"status":"aborted","timestamp":1686885887060,"user_tz":240,"elapsed":12,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["class RNN(torch.nn.Module):\n","    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=2, num_layers=2, dropout=0.2, bidirectional=False):\n","        super().__init__()\n","        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n","        self.rnn = torch.nn.GRU(\n","            input_size=embedding_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=num_layers,\n","            dropout=dropout if num_layers > 1 else 0,\n","            bidirectional=bidirectional\n","        )\n","        self.fc = torch.nn.Linear(2*hidden_dim if bidirectional else hidden_dim, output_dim)\n","\n","    def forward(self, text):\n","        #text = [sent len, batch size]\n","        embedded = self.embedding(text)\n","        #embedded = [sent len, batch size, emb dim]\n","        output, hidden = self.rnn(embedded)\n","        #output = [sent len, batch size, hid dim]\n","        y = self.fc(output[-1,:,:].squeeze(0))\n","        return y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L4fuOYyD_TBo"},"source":["> üí° A diferencia de los pots anteriores, ahora la dimensi√≥n *batch* NO es la primera. Este es el comportamiento por defecto de las capas recurrentes en `Pytorch`. Puedes modificar esto a√±adiendo la opci√≥n `batch_first=True` en la capa recurrente (y aseg√∫rate que tu dataloader utiliza tambi√©n la primera dimensi√≥n para el batch. En `torchtext` puedes indicarlo con el par√°metro `batch_first=True` a la hora de definir el `FIELD` en cuesti√≥n)."]},{"cell_type":"markdown","metadata":{"id":"0npmea43_TBo"},"source":["Como siempre, probamos que nuestra red est√© bien definida y las dimensiones encajen. A la entrada, esperamos tensores con dimensiones `longitud secuencia x batch`. Puedes verlo si sacamos unas muestras de nuestro dataloader."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.126961Z","start_time":"2020-09-01T16:40:10.964958Z"},"id":"sJmPnfCn_TBo","executionInfo":{"status":"aborted","timestamp":1686885887060,"user_tz":240,"elapsed":12,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["batch = next(iter(dataloader['train']))\n","\n","batch.text.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vxjTFY1Y_TBo"},"source":["Cada palabra estr√° representada por un √≠ndice, que luego el `embedding` usar√° para extraer el vector determinado que representa la palabra. A la salida, nuestro modelo nos dar√° dos valores. Si el primer valor es mayor que el segundo, asignaremos la clase `0` (opini√≥n negativa) y viceversa."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.254958Z","start_time":"2020-09-01T16:40:12.127961Z"},"id":"bsn5vWpq_TBo","executionInfo":{"status":"aborted","timestamp":1686885887061,"user_tz":240,"elapsed":13,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["model = RNN(input_dim=len(TEXT.vocab))\n","outputs = model(torch.randint(0, len(TEXT.vocab), (100, 64)))\n","outputs.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mBvroj3F_TBp"},"source":["## Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"xF8yaoDf_TBp"},"source":["Para entrenar nuestra red usamos el bucle est√°ndar que ya usamos en posts anteriores."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.270961Z","start_time":"2020-09-01T16:40:12.256959Z"},"code_folding":[],"id":"xpnh78ne_TBp","executionInfo":{"status":"aborted","timestamp":1686885887061,"user_tz":240,"elapsed":13,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["from tqdm import tqdm\n","import numpy as np\n","\n","def fit(model, dataloader, epochs=5):\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        train_loss, train_acc = [], []\n","        bar = tqdm(dataloader['train'])\n","        for batch in bar:\n","            X, y = batch.text, batch.label\n","            X, y = X.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(X)\n","            loss = criterion(y_hat, y)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss.append(loss.item())\n","            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","            train_acc.append(acc)\n","            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n","        bar = tqdm(dataloader['test'])\n","        val_loss, val_acc = [], []\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in bar:\n","                X, y = batch.text, batch.label\n","                X, y = X.to(device), y.to(device)\n","                y_hat = model(X)\n","                loss = criterion(y_hat, y)\n","                val_loss.append(loss.item())\n","                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","                val_acc.append(acc)\n","                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n","        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:22.941249Z","start_time":"2020-09-01T16:34:05.448274Z"},"id":"oCZ8ks03_TBp","executionInfo":{"status":"aborted","timestamp":1686885887063,"user_tz":240,"elapsed":15,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["fit(model, dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tBaI02Aw_TBq"},"source":["## Generando predicciones"]},{"cell_type":"markdown","metadata":{"id":"DOFrR-Q6_TBq"},"source":["Ahora ya podemos utilizar nuestro modelo para generar valoraciones de manera autom√°tica dada una opini√≥n."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:23.366252Z","start_time":"2020-09-01T16:36:22.942250Z"},"id":"9V62ITpe_TBq","executionInfo":{"status":"aborted","timestamp":1686885887064,"user_tz":240,"elapsed":16,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["import spacy\n","nlp = spacy.load('en')\n","\n","def predict(model, X):\n","    model.eval()\n","    with torch.no_grad():\n","        X = torch.tensor(X).to(device)\n","        pred = model(X)\n","        return pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:23.382248Z","start_time":"2020-09-01T16:36:23.367255Z"},"id":"DROufKjC_TBq","executionInfo":{"status":"aborted","timestamp":1686885887064,"user_tz":240,"elapsed":16,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\"]\n","tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n","indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n","tensor = torch.tensor(indexed).permute(1,0)\n","predictions = torch.argmax(predict(model, tensor), axis=1)\n","predictions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IuXAar62_TBq"},"source":["En este caso solo tenemos dos posibles clases, pero es f√°cil intuir que de ser capaces de construir un dataset con muchas m√°s clases que describan con mayor precisi√≥n el \"sentimiento\" en un texto podr√≠amos extraer much√≠sima informaci√≥n muy valiosa para, sobre todo, empresas que venden productos online m√°s all√° de las t√≠picas estrellas o puntuaciones que, pese a dar informaci√≥n valiosa, no aportan ning√∫n tipo de informaci√≥n accionable."]},{"cell_type":"markdown","metadata":{"id":"W_5ZV1VH_TBq"},"source":["## Redes Recurrentes Bidireccionales"]},{"cell_type":"markdown","metadata":{"id":"Js85VzSP_TBr"},"source":["Las redes recurrentes bidireccionales nos van a permitir, por norma general, obtener mejores resultados cuando trabajemos con datos secuenciales en los que \"podamos mirar al futuro\". En aplicaciones tales como la generaci√≥n de texto o la predicci√≥n de series temporales, esto no lo pod√≠amos hacer ya que el objetivo de la tarea es precisamente predecir valores futuros (y utilizar estos valores durante el entrenamiento no tendr√≠a sentido). Sin embargo, para la tarea de clasificaci√≥n de texto, s√≠ que podemos hacerlo.\n","\n","![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)\n","\n","Puedes conocer m√°s sobre este tipo de redes, as√≠ como otras mejoras, en este [post](https://sensioai.com/blog/036_rnn_mejoras)."]},{"cell_type":"code","metadata":{"ExecuteTime":{"start_time":"2020-09-01T16:39:19.400Z"},"id":"Wd7RVd_Q_TBr","executionInfo":{"status":"aborted","timestamp":1686885887065,"user_tz":240,"elapsed":17,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"}}},"source":["model = RNN(input_dim=len(TEXT.vocab), bidirectional=True)\n","fit(model, dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwNPlpXn_TBr"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"oACeo1Ns_TBr"},"source":["En este post hemos aprendido a utilizar `redes neuronales recurrentes` para la tarea de clasificaci√≥n de texto. Esta tarea es muy √∫til en la industria, sobre todo para aquellos negocios que venden productos o servicios cuyos usuarios pueden valorar directamente de manera online de forma masiva. Tener un sistema automatizado que \"lea\" todas las opiniones y las clasifique en clases con significado, puede aportar mucha informaci√≥n valiosa a una empresa sobre la cual puede llevar a cabo acciones de mejora de manera r√°pida. Como hemos visto, el uso de la librer√≠a `torchtext` nos facilita mucho la vida a la hora de procesar el texto, y gracias a su integraci√≥n con `Pytorch` podremos entrenar modelos de manera r√°pida y sencilla. Para esta tarea en concreto, tambi√©n hemos visto que el uso de `redes recurrentes bidireccionales` nos puede dar un extra de precisi√≥n."]}]}