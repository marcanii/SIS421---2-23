{"cells":[{"cell_type":"markdown","metadata":{"id":"zhGT_E_M1aK7"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/038_clasificacion_texto/clasificacion_texto.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"15jw75rR1aK9"},"source":["# Clasificación de texto"]},{"cell_type":"markdown","metadata":{"id":"kwR8ARoK1aK-"},"source":["En el [post](https://sensioai.com/blog/037_charRNN) anterior aprendimos a cómo podemos entrenar una `red neuronal recurrente` para generar texto letra a letra, una tarea muy interesante dentro del mundo del `procesado de lenguaje natur` o `NLP` (*natural language processing*) por sus siglas en inglés. Aún así, posiblemente la tarea más interesante desde un punto de vista práctico y con más aplicaciones en la industria sea la de `clasificación de texto`. De la misma manera que podemos entrenar `redes neuronales` para [clasificación de imágenes](https://sensioai.com/blog/033_receta_entrenamiento), es posible entrenar modelos de `machine learning` capaces de asignar una etiqueta determinada a un trozo de texto. Podemos encontrar este tipo de aplicaciones en redes sociales, por ejemplo, para detectar automáticamente mensaje ofensivos o en opiniones de usuarios sobre artículos para medir su satisfacción. En este post vamos a ver cómo podemos entrenar una `red neuronal recurrente` para clasificar *reviews* de películas, una tarea también conocida por el nombre de `sentiment analysis`."]},{"cell_type":"markdown","metadata":{"id":"2aEkLF551aK-"},"source":[" ## El *dataset*"]},{"cell_type":"markdown","metadata":{"id":"dn_S5JLi1aK-"},"source":["En el post anterior descargamos el libro *Don Quijote de la Mancha* en formato *txt*, luego lo cargamos en `Python` para proceder al proceso de `tokenización`. Si bien implementamos nuestra propia lógica de procesado de texto, a la práctica es más conveniente utilizar herramientas de terceros bien testeadas y optimizadas. Entre las diferentes librerías que existen de `NLP`, nosotros utilizaremos [torchtext](https://pytorch.org/text/) ya que está bien integrada con el ecosistema de `Pytorch`. "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110226,"status":"ok","timestamp":1655443545083,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"MGbSy6o0HGyG","outputId":"700a16e7-cbde-479c-90dc-12532776d943"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.10\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (4.64.0)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10) (4.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (1.24.3)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.12.0\n","    Uninstalling torchtext-0.12.0:\n","      Successfully uninstalled torchtext-0.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchtext-0.10.0\n"]}],"source":["!pip install torchtext==0.10"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:39:11.207060Z","start_time":"2020-09-01T16:39:10.641059Z"},"executionInfo":{"elapsed":756,"status":"ok","timestamp":1655443555199,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"KY4N4eFW1aK_"},"outputs":[],"source":["import torch\n","import torchtext\n","from torchtext.legacy import datasets\n","from torchtext.legacy import data\n","# from torchtext import datasets\n","# from torchtext import data"]},{"cell_type":"markdown","metadata":{"id":"_xao6-nk1aK_"},"source":["En `torchtext` tenemos disponible multitud de datasets que podemos utilizar, los cuales son ideales cuando estamos aprendiendo a trabajar con `redes neuronales` para tareas de `NLP`. En este caso descargaremos el dataset `IMDB` que contiene opiniones sobre películas. Nuestro objetivo será, dada una de estas *reviews* asignarle una etiqueta binaria (opinión positiva o negativa). "]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.615532Z","start_time":"2020-09-01T16:39:11.208061Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103726,"status":"ok","timestamp":1655443670063,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"7Wdxxl-51aK_","outputId":"3d4099d8-d16d-4f37-dfc6-779fb6ceb105"},"outputs":[{"name":"stdout","output_type":"stream","text":["downloading aclImdb_v1.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 33.7MB/s]\n"]}],"source":["TEXT = data.Field(tokenize = 'spacy')\n","LABEL = data.LabelField(dtype = torch.long)\n","\n","# fields = {'text': ('t', TEXT), 'label': ('l', LABEL)}\n","\n","# train_data, valid_data, test_data = TabularDataset.splits(path=path_datasets,\n","#                                                                train=\"lcquad10_train.csv\",\n","#                                                                test=\"lcquad10_test.csv\",\n","#                                                                validation=\"lcquad10_valid.csv\",\n","#                                                                format=\"csv\",\n","#                                                                fields=fields)\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"]},{"cell_type":"markdown","metadata":{"id":"lt5c2ZPu1aLA"},"source":["> ⚡ La clase `torchtext.data.Field` contiene toda la lógica de tokenización y procesado de texto necesaria, lo cual nos facilitará mucho la vida para esta tarea. Puedes aprender más sobre esta clase, y la librería en general, en su [documentación](https://pytorch.org/text/data.html)."]},{"cell_type":"markdown","metadata":{"id":"Cc36xGkN1aLB"},"source":["En este caso en concreto, disponemos de 25000 muestras tanto para el entrenamiento como evaluación de nuestros modelos."]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.632530Z","start_time":"2020-09-01T16:40:09.616535Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1655443681785,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"fV_YRLIR1aLB","outputId":"ec21bd36-5c75-495b-b705-8afd3f78c7d4"},"outputs":[{"data":{"text/plain":["(25000, 25000)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data), len(test_data)"]},{"cell_type":"markdown","metadata":{"id":"qsqtcsid1aLB"},"source":["De la siguiente manera podemos ver un ejemplo de muestra de nuestro dataset, que está compuesto por el texto y la valoración."]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.647529Z","start_time":"2020-09-01T16:40:09.633530Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1655443775831,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"zYUvduTQ1aLC","outputId":"972658fa-36b6-4ada-dc1d-9bdeab8d8212"},"outputs":[{"name":"stdout","output_type":"stream","text":["[<torchtext.legacy.data.example.Example object at 0x7f4c82d30210>, <torchtext.legacy.data.example.Example object at 0x7f4c7de50e10>, <torchtext.legacy.data.example.Example object at 0x7f4c7de5ef90>, <torchtext.legacy.data.example.Example object at 0x7f4c7de6b8d0>, <torchtext.legacy.data.example.Example object at 0x7f4c7e274790>, <torchtext.legacy.data.example.Example object at 0x7f4c7e2a7950>, <torchtext.legacy.data.example.Example object at 0x7f4c7e2ae6d0>, <torchtext.legacy.data.example.Example object at 0x7f4c81a32610>, <torchtext.legacy.data.example.Example object at 0x7f4c81a34350>, <torchtext.legacy.data.example.Example object at 0x7f4c81a4cc10>]\n","{'text': ['The', 'great', 'talents', 'of', 'Michael', 'Powell', 'and', 'Emeric', 'Pressberger', 'are', 'noticeable', 'in', 'their', 'wonderful', '\"', 'A', 'Matter', 'of', 'Life', 'and', 'Death', '\"', '.', 'It', 'was', 'part', 'of', 'the', 'recent', 'tribute', 'to', 'Mr.', 'Powell', 'that', 'played', 'at', 'the', 'Walter', 'Reade', 'in', 'New', 'York', '.', 'This', 'film', ',', 'in', 'particular', ',', 'shows', 'us', 'one', 'of', 'the', 'best', 'British', 'films', 'from', 'that', ',', 'or', 'any', 'other', 'era.<br', '/><br', '/>\"A', 'Matter', 'of', 'Life', 'and', 'Death', '\"', 'has', 'a', 'brilliant', 'cinematography', 'by', 'Jack', 'Cardiff', ',', 'a', 'man', 'who', 'knew', 'how', 'to', 'work', 'wonders', 'with', 'a', 'camera', '.', 'Particularly', 'impressive', 'is', 'the', 'contrast', 'from', 'the', 'monochromatic', 'tones', 'given', 'to', 'the', 'scenes', 'played', 'in', 'heaven', ',', 'and', 'the', 'colored', 'ones', 'when', 'the', 'action', 'comes', 'back', 'to', 'earth', '.', 'This', 'was', 'quite', 'a', 'coup', ',', 'and', 'well', 'ahead', 'of', 'its', 'times', '.', 'The', 'black', 'and', 'white', 'sequence', 'that', 'involves', 'the', 'long', 'staircase', 'where', 'Peter', 'and', 'the', 'Conductor', 'are', 'chatting', 'has', 'to', 'be', 'one', 'of', 'the', 'most', 'amazing', 'things', 'on', 'any', 'film.<br', '/><br', '/>Much', 'has', 'been', 'said', 'in', 'this', 'forum', 'about', 'the', 'film', ',', 'so', 'our', 'comment', 'will', 'be', 'about', 'the', 'great', 'acting', 'Powell', 'and', 'Pressberger', 'got', 'out', 'of', 'the', 'large', ',', 'distinguished', 'cast', ',', 'who', 'responded', 'magnificently', 'to', 'the', 'directors', \"'\", 'guidance.<br', '/><br', '/>David', 'Niven', ',', 'is', 'Peter', ',', 'whose', 'aircraft', 'is', 'hit', 'and', 'his', 'best', 'friend', 'dies', 'as', 'a', 'result', 'of', 'it', '.', 'This', 'film', 'marked', 'one', 'of', 'the', 'highlights', 'in', 'Mr.', 'Niven', \"'s\", 'career', '.', 'He', 'was', 'an', 'excellent', 'film', 'actor', 'as', 'he', 'shows', 'us', 'in', 'this', 'movie', '.', 'Kim', 'Hunter', 'is', 'surprisingly', 'good', 'as', 'June', ',', 'the', 'woman', 'who', 'talked', 'to', 'Peter', 'as', 'his', 'plane', 'was', 'falling', 'from', 'the', 'skies', '.', 'As', 'fate', 'would', 'have', 'it', ',', 'Peter', 'and', 'June', 'fall', 'in', 'love', 'at', 'first', 'sight.<br', '/><br', '/>Some', 'of', 'the', 'best', 'British', 'film', 'actors', 'grace', 'this', 'film', 'with', 'their', 'presence', '.', 'Robert', 'Coote', ',', 'is', 'Bob', ',', 'the', 'man', 'who', 'is', 'admitted', 'to', 'heaven', ',', 'but', 'he', 'is', 'surprised', 'his', 'friend', 'Peter', 'never', 'made', 'the', 'trip', 'with', 'him', '.', 'An', 'excellent', 'star', 'turn', 'by', 'Marius', 'Goring', ',', 'who', 'as', 'the', 'Conductor', '71', 'steals', 'the', 'film', '.', 'Mr.', 'Goring', ',', 'who', 'had', 'worked', 'with', 'the', 'directors', ',', 'is', 'one', 'of', 'the', 'best', 'things', 'in', 'the', 'movie', '.', 'Also', ',', 'Roger', 'Livesey', ',', 'as', 'Dr.', 'Frank', 'Reeves', ',', 'does', 'one', 'of', 'the', 'best', 'appearances', 'of', 'his', 'career', ',', 'as', 'well', 'as', 'Raymond', 'Massey', ',', 'who', 'is', 'seen', 'as', 'Abraham', 'Farlan.<br', '/><br', '/>\"A', 'Matter', 'of', 'Life', 'and', 'Death', '\"', 'is', 'a', 'timeless', 'film', 'that', 'will', 'always', 'be', 'seen', 'with', 'gratitude', 'toward', 'its', 'creators', '.'], 'label': 'pos'}\n"]}],"source":["print(train_data[0:10])\n","print(vars(train_data.examples[0]))"]},{"cell_type":"markdown","metadata":{"id":"gwp4mQMf1aLC"},"source":["### Tokenización"]},{"cell_type":"markdown","metadata":{"id":"IC2oA0-j1aLC"},"source":["Además de proveernos con varios datasets, `torchtext` también nos facilita mucho la vida a la hora de llevar a cabo el proceso de `tokenización`. En este caso vamos a construir un vocabulario que contendrá un número determinado de palabras (ya que si aqueremos incluirlas los requisitos computacionales se dispararían). Para ello el tokenizador calculará la frecuencia de cada palabra en el texto y se quedará con la cantidad que especifiquemos."]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.841436Z","start_time":"2020-09-01T16:40:09.648529Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1394,"status":"ok","timestamp":1655444147571,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"XngbeyGP1aLC","outputId":"947b219a-3b27-4465-c451-69f19e762beb"},"outputs":[{"data":{"text/plain":["(10002, 2)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["MAX_VOCAB_SIZE = 10000\n","\n","TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n","LABEL.build_vocab(train_data)\n","\n","len(TEXT.vocab), len(LABEL.vocab)"]},{"cell_type":"markdown","metadata":{"id":"FWSbnptv1aLC"},"source":["Como pudes ver tenemos un vocabulario con la longitud determinada más dos, estos dos *tokens* extra corresponden a los *tokens* `<unk>`, que se le asignarán a las palabras desconocidas y las menos frecuentes que no hayan pasado el primer filtro, y el *token* `<pad>`, que se usará para que todas las frases en un *batch* tengan la misma longitud (necesitamos tensores recutangulares para entrenar nuestra red)."]},{"cell_type":"code","execution_count":10,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.883957Z","start_time":"2020-09-01T16:40:10.843442Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1655444162684,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Lg6DNFOZ1aLD","outputId":"1503d8aa-e397-47f7-c96e-72548ce116aa"},"outputs":[{"data":{"text/plain":["[('the', 289838),\n"," (',', 275296),\n"," ('.', 236843),\n"," ('and', 156483),\n"," ('a', 156282),\n"," ('of', 144055),\n"," ('to', 133886),\n"," ('is', 109095),\n"," ('in', 87676),\n"," ('I', 77546)]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.freqs.most_common(10)\n","# TEXT.vocab.stoi\n","# TEXT.vocab.itos"]},{"cell_type":"code","execution_count":11,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.899961Z","start_time":"2020-09-01T16:40:10.885959Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1655444167427,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"EfssHS581aLD","outputId":"57b5c5a8-b996-402b-e572-4f3b00d29ba6"},"outputs":[{"data":{"text/plain":["['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.itos[:10]"]},{"cell_type":"code","execution_count":12,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.915962Z","start_time":"2020-09-01T16:40:10.900958Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1655444172833,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"y0pl1I7K1aLD","outputId":"15d46548-750b-4f2c-fabf-f8ae12517509"},"outputs":[{"data":{"text/plain":["defaultdict(None, {'neg': 0, 'pos': 1})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["LABEL.vocab.stoi"]},{"cell_type":"markdown","metadata":{"id":"2RheZpDK1aLD"},"source":["El último paso para tener nuestros datos listos para entrenar una red neuronal es construir el `DataLoader` encargado de alimentar nuestra red con *batches* de frases de manera eficiente. Para ello utilizamos la clase `torchtext.data.BucketIterator`, que además juntará frases de similar longitud minimazndo el *padding* necesario."]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.947957Z","start_time":"2020-09-01T16:40:10.916958Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1655444202139,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Ml7Nv-Eu1aLE","outputId":"694b1f18-e815-494e-c7fe-9a12add10a7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","\n","dataloader = {\n","    'train': data.BucketIterator(train_data, batch_size=128, shuffle=True, sort_within_batch=True, device=device),\n","    'test': data.BucketIterator(test_data, batch_size=128, device=device)\n","}"]},{"cell_type":"markdown","metadata":{"id":"ouJM_T9a1aLE"},"source":["## El modelo"]},{"cell_type":"markdown","metadata":{"id":"-cfFgRSx1aLE"},"source":["Para poder clasificar texto utilizaremos una [red recurrente](https://sensioai.com/blog/034_rnn_intro) de tipo `many-to-one`, la cual recibirá el texto palabra por palabra. Usaremos el último estado oculto (el cual contendrá información de toda la frase) para generar nuestra predicción final. Cada palabra estará representada por un vector, el cual será aprendido por la red en la capa `embedding` (puedes aprender más sobre esta capa en nuestro [post](https://sensioai.com/blog/037_charRNN) anterior)."]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.963957Z","start_time":"2020-09-01T16:40:10.948957Z"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1655444221340,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"rJNO9kOZ1aLE"},"outputs":[],"source":["class RNN(torch.nn.Module):\n","    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=2, num_layers=2, dropout=0.2, bidirectional=False):\n","        super().__init__()\n","        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n","        self.rnn = torch.nn.GRU(\n","            input_size=embedding_dim, \n","            hidden_size=hidden_dim, \n","            num_layers=num_layers, \n","            dropout=dropout if num_layers > 1 else 0,\n","            bidirectional=bidirectional\n","        )\n","        self.fc = torch.nn.Linear(2*hidden_dim if bidirectional else hidden_dim, output_dim)\n","        \n","    def forward(self, text):\n","        #text = [sent len, batch size]        \n","        embedded = self.embedding(text)        \n","        #embedded = [sent len, batch size, emb dim]        \n","        output, hidden = self.rnn(embedded)        \n","        #output = [sent len, batch size, hid dim]\n","        y = self.fc(output[-1,:,:].squeeze(0))     \n","        return y"]},{"cell_type":"markdown","metadata":{"id":"1K_4JoIv1aLF"},"source":["> 💡 A diferencia de los pots anteriores, ahora la dimensión *batch* NO es la primera. Este es el comportamiento por defecto de las capas recurrentes en `Pytorch`. Puedes modificar esto añadiendo la opción `batch_first=True` en la capa recurrente (y asegúrate que tu dataloader utiliza también la primera dimensión para el batch. En `torchtext` puedes indicarlo con el parámetro `batch_first=True` a la hora de definir el `FIELD` en cuestión). "]},{"cell_type":"markdown","metadata":{"id":"VodE6Tds1aLF"},"source":["Como siempre, probamos que nuestra red esté bien definida y las dimensiones encajen. A la entrada, esperamos tensores con dimensiones `longitud secuencia x batch`. Puedes verlo si sacamos unas muestras de nuestro dataloader."]},{"cell_type":"code","execution_count":15,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.126961Z","start_time":"2020-09-01T16:40:10.964958Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3916,"status":"ok","timestamp":1655444274520,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"ppg4-u4D1aLG","outputId":"b1cf6539-17ef-4b22-ef4f-5a192d82cb68"},"outputs":[{"data":{"text/plain":["torch.Size([349, 128])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["batch = next(iter(dataloader['train']))\n","\n","batch.text.shape"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1655444873317,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"_oXNdt-jLtet","outputId":"6d2cf78d-3aef-4585-b701-b5306cf71f96"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([  11,   73,  819,    8,  959,   16,   28,  131, 5971,    3,   26,   19,\n","         232,   21,    2, 1009,    3,   44,    3,   20,    6, 1014, 3113,    3,\n","         716, 7824, 6030, 1606,    5, 3318, 1331,   21,    2,  957,   14,    0,\n","          88,  291,   60,    3,   26,  156,  172,   33,   10,    2, 1355,   23,\n","          13,   22,    4,   14, 4716,    0,    2,   14,    0,    0, 1192,    0,\n","          18, 3011,    3,   11,  276,    0,  503,    0,    6,  274,  777,   22,\n","           4,  555, 1292, 1049, 2725,    3,   12,   85,   34,  410,    7,  277,\n","           5,    6,  186,  488,   55, 1332,  410,    4,   11,   19, 8623,   21,\n","           2,  211,   13,   12,   19,    6, 1047,    3,    5,   20,    6, 1014,\n","        3113,  130,  117,  285,    8, 3085,   13,  211,    5,  130,  109,   28,\n","          79,  218, 5432, 1077,    4,  764, 7298, 1477,   10,    6, 2041,    5,\n","        1489, 2103,   20,    6,    0, 2375,    0,   13,    3,   23,    2,  105,\n","         197,  338,   84, 1570,  127,  213,   88,  529,    4,   63,   30,  212,\n","         240,   36,  147,   76,  614, 7298,  295,   10,    6,  756,  713,  909,\n","        2103,   58,    5,  327,    4,  558,   57,   45,  107, 1252,    0,   13,\n","         191,  178,    5, 8561,    3,    5,  111,  744,   57,   45, 8081,  142,\n","          58,   25,  196,    3,   42,  512,  174,   10,   79,  218,  233,    3,\n","         295,   10,    6,  103,  316,    3,    5,   31,   93,    2, 1401,   13,\n","          45,   73,    6,   60,   68,  808,  328,   71,    9, 1049,  700,   10,\n","           6,   22,   47,   16,    4, 5344,    8,  151,   42,   85,   33,  167,\n","          20, 4531,   10,   16,   22,    3,  247,  129,   17, 1658,    5,  514,\n","          17, 1658,    3,   26,   12,  104,   84, 1013,   55,    2,  342,  966,\n","           5, 1223,  176,    2,  220,    3,   48,   11, 1223,   12,    6, 1068,\n","          39, 6640,   16,   38,   23,    6,   60,   68,    3,  451, 4605,    6,\n","         186,  396,    5,    6,    0,    4,   31,  264,   34,    6,   60, 1783,\n","          18,    0,   18, 2656,    6,  538, 1032,    3,    2,  847,    9, 2162,\n","           4,   54,   15,  103,    8,  860,    2,  257,  507, 2662,    0,    0,\n","         362,    3,    5,   12,  338,   84,    0,    0,    7,    2,  642,  222,\n","         139,    2,  942, 5268,    4,    1,    1,    1,    1,    1,    1,    1,\n","           1], device='cuda:0')\n"]}],"source":["print(batch.text[:, 127])"]},{"cell_type":"markdown","metadata":{"id":"BszMI43L1aLG"},"source":["Cada palabra estrá representada por un índice, que luego el `embedding` usará para extraer el vector determinado que representa la palabra. A la salida, nuestro modelo nos dará dos valores. Si el primer valor es mayor que el segundo, asignaremos la clase `0` (opinión negativa) y viceversa."]},{"cell_type":"code","execution_count":27,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.254958Z","start_time":"2020-09-01T16:40:12.127961Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1655444898684,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"0N81nFz61aLG","outputId":"cb55535f-f06c-4563-afd8-6281634cc180"},"outputs":[{"data":{"text/plain":["torch.Size([64, 2])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["model = RNN(input_dim=len(TEXT.vocab))\n","outputs = model(torch.randint(0, len(TEXT.vocab), (100, 64)))\n","outputs.shape"]},{"cell_type":"markdown","metadata":{"id":"Uz0cz_Pl1aLG"},"source":["## Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"UMEP9r8f1aLH"},"source":["Para entrenar nuestra red usamos el bucle estándar que ya usamos en posts anteriores."]},{"cell_type":"code","execution_count":28,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.270961Z","start_time":"2020-09-01T16:40:12.256959Z"},"code_folding":[],"executionInfo":{"elapsed":278,"status":"ok","timestamp":1655444905379,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"d3hf2Ns-1aLH"},"outputs":[],"source":["from tqdm import tqdm\n","import numpy as np\n","\n","def fit(model, dataloader, epochs=5):\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        train_loss, train_acc = [], []\n","        bar = tqdm(dataloader['train'])\n","        for batch in bar:\n","            X, y = batch.text, batch.label\n","            X, y = X.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(X)\n","            loss = criterion(y_hat, y)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss.append(loss.item())\n","            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","            train_acc.append(acc)\n","            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n","        bar = tqdm(dataloader['test'])\n","        val_loss, val_acc = [], []\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in bar:\n","                X, y = batch.text, batch.label\n","                X, y = X.to(device), y.to(device)\n","                y_hat = model(X)\n","                loss = criterion(y_hat, y)\n","                val_loss.append(loss.item())\n","                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","                val_acc.append(acc)\n","                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n","        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"]},{"cell_type":"code","execution_count":29,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:22.941249Z","start_time":"2020-09-01T16:34:05.448274Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104260,"status":"ok","timestamp":1655445015624,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"NAozFomA1aLH","outputId":"a249dff8-082b-4686-e348-c0aaf6e55cf0"},"outputs":[{"name":"stderr","output_type":"stream","text":["loss 0.66552 acc 0.58906: 100%|██████████| 196/196 [00:09<00:00, 20.57it/s]\n","val_loss 0.71261 val_acc 0.50197: 100%|██████████| 196/196 [00:11<00:00, 17.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5 loss 0.66552 val_loss 0.71261 acc 0.58906 val_acc 0.50197\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.52902 acc 0.73838: 100%|██████████| 196/196 [00:09<00:00, 20.82it/s]\n","val_loss 1.11421 val_acc 0.50759: 100%|██████████| 196/196 [00:11<00:00, 17.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/5 loss 0.52902 val_loss 1.11421 acc 0.73838 val_acc 0.50759\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.40182 acc 0.82474: 100%|██████████| 196/196 [00:09<00:00, 20.64it/s]\n","val_loss 0.36842 val_acc 0.84211: 100%|██████████| 196/196 [00:11<00:00, 17.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/5 loss 0.40182 val_loss 0.36842 acc 0.82474 val_acc 0.84211\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.28718 acc 0.88057: 100%|██████████| 196/196 [00:09<00:00, 20.77it/s]\n","val_loss 0.31013 val_acc 0.87338: 100%|██████████| 196/196 [00:11<00:00, 17.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/5 loss 0.28718 val_loss 0.31013 acc 0.88057 val_acc 0.87338\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.23763 acc 0.90740: 100%|██████████| 196/196 [00:09<00:00, 20.80it/s]\n","val_loss 0.27751 val_acc 0.88396: 100%|██████████| 196/196 [00:11<00:00, 17.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/5 loss 0.23763 val_loss 0.27751 acc 0.90740 val_acc 0.88396\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["fit(model, dataloader)"]},{"cell_type":"markdown","metadata":{"id":"DDA6J8a71aLH"},"source":["## Generando predicciones"]},{"cell_type":"markdown","metadata":{"id":"phO7Cjel1aLI"},"source":["Ahora ya podemos utilizar nuestro modelo para generar valoraciones de manera automática dada una opinión."]},{"cell_type":"code","execution_count":30,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:23.366252Z","start_time":"2020-09-01T16:36:22.942250Z"},"executionInfo":{"elapsed":620,"status":"ok","timestamp":1655445785047,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"_ZXaSu7H1aLI"},"outputs":[],"source":["import spacy\n","nlp = spacy.load('en')\n","\n","def predict(model, X):\n","    model.eval() \n","    with torch.no_grad():\n","        X = torch.tensor(X).to(device)\n","        pred = model(X)\n","        return pred"]},{"cell_type":"code","execution_count":31,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:23.382248Z","start_time":"2020-09-01T16:36:23.367255Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1655445787316,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"1Svs5FC_1aLI","outputId":"3e3c5955-e98a-42a4-825e-ad4184cd71ca"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n"]},{"data":{"text/plain":["tensor([0, 1, 1, 0, 0], device='cuda:0')"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\", \"I hate it.\"]\n","tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n","indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n","tensor = torch.tensor(indexed).permute(1,0)\n","predictions = torch.argmax(predict(model, tensor), axis=1)\n","predictions"]},{"cell_type":"markdown","metadata":{"id":"Xps6nej_1aLI"},"source":["En este caso solo tenemos dos posibles clases, pero es fácil intuir que de ser capaces de construir un dataset con muchas más clases que describan con mayor precisión el \"sentimiento\" en un texto podríamos extraer muchísima información muy valiosa para, sobre todo, empresas que venden productos online más allá de las típicas estrellas o puntuaciones que, pese a dar información valiosa, no aportan ningún tipo de información accionable."]},{"cell_type":"markdown","metadata":{"id":"3875mz_T1aLI"},"source":["## Redes Recurrentes Bidireccionales"]},{"cell_type":"markdown","metadata":{"id":"OpHNbNgF1aLJ"},"source":["Las redes recurrentes bidireccionales nos van a permitir, por norma general, obtener mejores resultados cuando trabajemos con datos secuenciales en los que \"podamos mirar al futuro\". En aplicaciones tales como la generación de texto o la predicción de series temporales, esto no lo podíamos hacer ya que el objetivo de la tarea es precisamente predecir valores futuros (y utilizar estos valores durante el entrenamiento no tendría sentido). Sin embargo, para la tarea de clasificación de texto, sí que podemos hacerlo.\n","\n","![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)\n","\n","Puedes conocer más sobre este tipo de redes, así como otras mejoras, en este [post](https://sensioai.com/blog/036_rnn_mejoras)."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"start_time":"2020-09-01T16:39:19.400Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"1wBGQVIx1aLJ","outputId":"b7800469-338e-4783-f01c-f1aa0c8d2fd3"},"outputs":[{"name":"stderr","output_type":"stream","text":["loss 0.65129 acc 0.60130: 100%|██████████| 196/196 [00:16<00:00, 11.58it/s]\n","val_loss 0.63835 val_acc 0.52760: 100%|██████████| 196/196 [00:18<00:00, 10.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5 loss 0.65129 val_loss 0.63835 acc 0.60130 val_acc 0.52760\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.47277 acc 0.78142:  23%|██▎       | 45/196 [00:03<00:11, 12.85it/s]"]}],"source":["model = RNN(input_dim=len(TEXT.vocab), bidirectional=True)\n","fit(model, dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:23.382248Z","start_time":"2020-09-01T16:36:23.367255Z"},"id":"QbfZybjuo5fO"},"outputs":[],"source":["sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\", \"so good bad film\", \"so little bad good\"]\n","tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n","indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n","tensor = torch.tensor(indexed).permute(1,0)\n","predictions = torch.argmax(predict(model, tensor), axis=1)\n","predictions"]},{"cell_type":"markdown","metadata":{"id":"fHajFJBc1aLJ"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"M32ASRDl1aLJ"},"source":["En este post hemos aprendido a utilizar `redes neuronales recurrentes` para la tarea de clasificación de texto. Esta tarea es muy útil en la industria, sobre todo para aquellos negocios que venden productos o servicios cuyos usuarios pueden valorar directamente de manera online de forma masiva. Tener un sistema automatizado que \"lea\" todas las opiniones y las clasifique en clases con significado, puede aportar mucha información valiosa a una empresa sobre la cual puede llevar a cabo acciones de mejora de manera rápida. Como hemos visto, el uso de la librería `torchtext` nos facilita mucho la vida a la hora de procesar el texto, y gracias a su integración con `Pytorch` podremos entrenar modelos de manera rápida y sencilla. Para esta tarea en concreto, también hemos visto que el uso de `redes recurrentes bidireccionales` nos puede dar un extra de precisión."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"clasificacion_texto.ipynb","provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/038_clasificacion_texto/clasificacion_texto.ipynb","timestamp":1623377428250}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}
