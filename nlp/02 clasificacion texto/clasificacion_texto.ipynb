{"cells":[{"cell_type":"markdown","metadata":{"id":"zhGT_E_M1aK7"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/038_clasificacion_texto/clasificacion_texto.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"15jw75rR1aK9"},"source":["# Clasificaci√≥n de texto"]},{"cell_type":"markdown","metadata":{"id":"kwR8ARoK1aK-"},"source":["En el [post](https://sensioai.com/blog/037_charRNN) anterior aprendimos a c√≥mo podemos entrenar una `red neuronal recurrente` para generar texto letra a letra, una tarea muy interesante dentro del mundo del `procesado de lenguaje natur` o `NLP` (*natural language processing*) por sus siglas en ingl√©s. A√∫n as√≠, posiblemente la tarea m√°s interesante desde un punto de vista pr√°ctico y con m√°s aplicaciones en la industria sea la de `clasificaci√≥n de texto`. De la misma manera que podemos entrenar `redes neuronales` para [clasificaci√≥n de im√°genes](https://sensioai.com/blog/033_receta_entrenamiento), es posible entrenar modelos de `machine learning` capaces de asignar una etiqueta determinada a un trozo de texto. Podemos encontrar este tipo de aplicaciones en redes sociales, por ejemplo, para detectar autom√°ticamente mensaje ofensivos o en opiniones de usuarios sobre art√≠culos para medir su satisfacci√≥n. En este post vamos a ver c√≥mo podemos entrenar una `red neuronal recurrente` para clasificar *reviews* de pel√≠culas, una tarea tambi√©n conocida por el nombre de `sentiment analysis`."]},{"cell_type":"markdown","metadata":{"id":"2aEkLF551aK-"},"source":[" ## El *dataset*"]},{"cell_type":"markdown","metadata":{"id":"dn_S5JLi1aK-"},"source":["En el post anterior descargamos el libro *Don Quijote de la Mancha* en formato *txt*, luego lo cargamos en `Python` para proceder al proceso de `tokenizaci√≥n`. Si bien implementamos nuestra propia l√≥gica de procesado de texto, a la pr√°ctica es m√°s conveniente utilizar herramientas de terceros bien testeadas y optimizadas. Entre las diferentes librer√≠as que existen de `NLP`, nosotros utilizaremos [torchtext](https://pytorch.org/text/) ya que est√° bien integrada con el ecosistema de `Pytorch`. "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110226,"status":"ok","timestamp":1655443545083,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"MGbSy6o0HGyG","outputId":"700a16e7-cbde-479c-90dc-12532776d943"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.10\n","  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (4.64.0)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 831.4 MB 2.8 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10) (4.2.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (1.24.3)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.12.0\n","    Uninstalling torchtext-0.12.0:\n","      Successfully uninstalled torchtext-0.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0 torchtext-0.10.0\n"]}],"source":["!pip install torchtext==0.10"]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:39:11.207060Z","start_time":"2020-09-01T16:39:10.641059Z"},"executionInfo":{"elapsed":756,"status":"ok","timestamp":1655443555199,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"KY4N4eFW1aK_"},"outputs":[],"source":["import torch\n","import torchtext\n","from torchtext.legacy import datasets\n","from torchtext.legacy import data\n","# from torchtext import datasets\n","# from torchtext import data"]},{"cell_type":"markdown","metadata":{"id":"_xao6-nk1aK_"},"source":["En `torchtext` tenemos disponible multitud de datasets que podemos utilizar, los cuales son ideales cuando estamos aprendiendo a trabajar con `redes neuronales` para tareas de `NLP`. En este caso descargaremos el dataset `IMDB` que contiene opiniones sobre pel√≠culas. Nuestro objetivo ser√°, dada una de estas *reviews* asignarle una etiqueta binaria (opini√≥n positiva o negativa). "]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.615532Z","start_time":"2020-09-01T16:39:11.208061Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103726,"status":"ok","timestamp":1655443670063,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"7Wdxxl-51aK_","outputId":"3d4099d8-d16d-4f37-dfc6-779fb6ceb105"},"outputs":[{"name":"stdout","output_type":"stream","text":["downloading aclImdb_v1.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["aclImdb_v1.tar.gz: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84.1M/84.1M [00:02<00:00, 33.7MB/s]\n"]}],"source":["TEXT = data.Field(tokenize = 'spacy')\n","LABEL = data.LabelField(dtype = torch.long)\n","\n","# fields = {'text': ('t', TEXT), 'label': ('l', LABEL)}\n","\n","# train_data, valid_data, test_data = TabularDataset.splits(path=path_datasets,\n","#                                                                train=\"lcquad10_train.csv\",\n","#                                                                test=\"lcquad10_test.csv\",\n","#                                                                validation=\"lcquad10_valid.csv\",\n","#                                                                format=\"csv\",\n","#                                                                fields=fields)\n","\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"]},{"cell_type":"markdown","metadata":{"id":"lt5c2ZPu1aLA"},"source":["> ‚ö° La clase `torchtext.data.Field` contiene toda la l√≥gica de tokenizaci√≥n y procesado de texto necesaria, lo cual nos facilitar√° mucho la vida para esta tarea. Puedes aprender m√°s sobre esta clase, y la librer√≠a en general, en su [documentaci√≥n](https://pytorch.org/text/data.html)."]},{"cell_type":"markdown","metadata":{"id":"Cc36xGkN1aLB"},"source":["En este caso en concreto, disponemos de 25000 muestras tanto para el entrenamiento como evaluaci√≥n de nuestros modelos."]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.632530Z","start_time":"2020-09-01T16:40:09.616535Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1655443681785,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"fV_YRLIR1aLB","outputId":"ec21bd36-5c75-495b-b705-8afd3f78c7d4"},"outputs":[{"data":{"text/plain":["(25000, 25000)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data), len(test_data)"]},{"cell_type":"markdown","metadata":{"id":"qsqtcsid1aLB"},"source":["De la siguiente manera podemos ver un ejemplo de muestra de nuestro dataset, que est√° compuesto por el texto y la valoraci√≥n."]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:09.647529Z","start_time":"2020-09-01T16:40:09.633530Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1655443775831,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"zYUvduTQ1aLC","outputId":"972658fa-36b6-4ada-dc1d-9bdeab8d8212"},"outputs":[{"name":"stdout","output_type":"stream","text":["[<torchtext.legacy.data.example.Example object at 0x7f4c82d30210>, <torchtext.legacy.data.example.Example object at 0x7f4c7de50e10>, <torchtext.legacy.data.example.Example object at 0x7f4c7de5ef90>, <torchtext.legacy.data.example.Example object at 0x7f4c7de6b8d0>, <torchtext.legacy.data.example.Example object at 0x7f4c7e274790>, <torchtext.legacy.data.example.Example object at 0x7f4c7e2a7950>, <torchtext.legacy.data.example.Example object at 0x7f4c7e2ae6d0>, <torchtext.legacy.data.example.Example object at 0x7f4c81a32610>, <torchtext.legacy.data.example.Example object at 0x7f4c81a34350>, <torchtext.legacy.data.example.Example object at 0x7f4c81a4cc10>]\n","{'text': ['The', 'great', 'talents', 'of', 'Michael', 'Powell', 'and', 'Emeric', 'Pressberger', 'are', 'noticeable', 'in', 'their', 'wonderful', '\"', 'A', 'Matter', 'of', 'Life', 'and', 'Death', '\"', '.', 'It', 'was', 'part', 'of', 'the', 'recent', 'tribute', 'to', 'Mr.', 'Powell', 'that', 'played', 'at', 'the', 'Walter', 'Reade', 'in', 'New', 'York', '.', 'This', 'film', ',', 'in', 'particular', ',', 'shows', 'us', 'one', 'of', 'the', 'best', 'British', 'films', 'from', 'that', ',', 'or', 'any', 'other', 'era.<br', '/><br', '/>\"A', 'Matter', 'of', 'Life', 'and', 'Death', '\"', 'has', 'a', 'brilliant', 'cinematography', 'by', 'Jack', 'Cardiff', ',', 'a', 'man', 'who', 'knew', 'how', 'to', 'work', 'wonders', 'with', 'a', 'camera', '.', 'Particularly', 'impressive', 'is', 'the', 'contrast', 'from', 'the', 'monochromatic', 'tones', 'given', 'to', 'the', 'scenes', 'played', 'in', 'heaven', ',', 'and', 'the', 'colored', 'ones', 'when', 'the', 'action', 'comes', 'back', 'to', 'earth', '.', 'This', 'was', 'quite', 'a', 'coup', ',', 'and', 'well', 'ahead', 'of', 'its', 'times', '.', 'The', 'black', 'and', 'white', 'sequence', 'that', 'involves', 'the', 'long', 'staircase', 'where', 'Peter', 'and', 'the', 'Conductor', 'are', 'chatting', 'has', 'to', 'be', 'one', 'of', 'the', 'most', 'amazing', 'things', 'on', 'any', 'film.<br', '/><br', '/>Much', 'has', 'been', 'said', 'in', 'this', 'forum', 'about', 'the', 'film', ',', 'so', 'our', 'comment', 'will', 'be', 'about', 'the', 'great', 'acting', 'Powell', 'and', 'Pressberger', 'got', 'out', 'of', 'the', 'large', ',', 'distinguished', 'cast', ',', 'who', 'responded', 'magnificently', 'to', 'the', 'directors', \"'\", 'guidance.<br', '/><br', '/>David', 'Niven', ',', 'is', 'Peter', ',', 'whose', 'aircraft', 'is', 'hit', 'and', 'his', 'best', 'friend', 'dies', 'as', 'a', 'result', 'of', 'it', '.', 'This', 'film', 'marked', 'one', 'of', 'the', 'highlights', 'in', 'Mr.', 'Niven', \"'s\", 'career', '.', 'He', 'was', 'an', 'excellent', 'film', 'actor', 'as', 'he', 'shows', 'us', 'in', 'this', 'movie', '.', 'Kim', 'Hunter', 'is', 'surprisingly', 'good', 'as', 'June', ',', 'the', 'woman', 'who', 'talked', 'to', 'Peter', 'as', 'his', 'plane', 'was', 'falling', 'from', 'the', 'skies', '.', 'As', 'fate', 'would', 'have', 'it', ',', 'Peter', 'and', 'June', 'fall', 'in', 'love', 'at', 'first', 'sight.<br', '/><br', '/>Some', 'of', 'the', 'best', 'British', 'film', 'actors', 'grace', 'this', 'film', 'with', 'their', 'presence', '.', 'Robert', 'Coote', ',', 'is', 'Bob', ',', 'the', 'man', 'who', 'is', 'admitted', 'to', 'heaven', ',', 'but', 'he', 'is', 'surprised', 'his', 'friend', 'Peter', 'never', 'made', 'the', 'trip', 'with', 'him', '.', 'An', 'excellent', 'star', 'turn', 'by', 'Marius', 'Goring', ',', 'who', 'as', 'the', 'Conductor', '71', 'steals', 'the', 'film', '.', 'Mr.', 'Goring', ',', 'who', 'had', 'worked', 'with', 'the', 'directors', ',', 'is', 'one', 'of', 'the', 'best', 'things', 'in', 'the', 'movie', '.', 'Also', ',', 'Roger', 'Livesey', ',', 'as', 'Dr.', 'Frank', 'Reeves', ',', 'does', 'one', 'of', 'the', 'best', 'appearances', 'of', 'his', 'career', ',', 'as', 'well', 'as', 'Raymond', 'Massey', ',', 'who', 'is', 'seen', 'as', 'Abraham', 'Farlan.<br', '/><br', '/>\"A', 'Matter', 'of', 'Life', 'and', 'Death', '\"', 'is', 'a', 'timeless', 'film', 'that', 'will', 'always', 'be', 'seen', 'with', 'gratitude', 'toward', 'its', 'creators', '.'], 'label': 'pos'}\n"]}],"source":["print(train_data[0:10])\n","print(vars(train_data.examples[0]))"]},{"cell_type":"markdown","metadata":{"id":"gwp4mQMf1aLC"},"source":["### Tokenizaci√≥n"]},{"cell_type":"markdown","metadata":{"id":"IC2oA0-j1aLC"},"source":["Adem√°s de proveernos con varios datasets, `torchtext` tambi√©n nos facilita mucho la vida a la hora de llevar a cabo el proceso de `tokenizaci√≥n`. En este caso vamos a construir un vocabulario que contendr√° un n√∫mero determinado de palabras (ya que si aqueremos incluirlas los requisitos computacionales se disparar√≠an). Para ello el tokenizador calcular√° la frecuencia de cada palabra en el texto y se quedar√° con la cantidad que especifiquemos."]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.841436Z","start_time":"2020-09-01T16:40:09.648529Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1394,"status":"ok","timestamp":1655444147571,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"XngbeyGP1aLC","outputId":"947b219a-3b27-4465-c451-69f19e762beb"},"outputs":[{"data":{"text/plain":["(10002, 2)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["MAX_VOCAB_SIZE = 10000\n","\n","TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n","LABEL.build_vocab(train_data)\n","\n","len(TEXT.vocab), len(LABEL.vocab)"]},{"cell_type":"markdown","metadata":{"id":"FWSbnptv1aLC"},"source":["Como pudes ver tenemos un vocabulario con la longitud determinada m√°s dos, estos dos *tokens* extra corresponden a los *tokens* `<unk>`, que se le asignar√°n a las palabras desconocidas y las menos frecuentes que no hayan pasado el primer filtro, y el *token* `<pad>`, que se usar√° para que todas las frases en un *batch* tengan la misma longitud (necesitamos tensores recutangulares para entrenar nuestra red)."]},{"cell_type":"code","execution_count":10,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.883957Z","start_time":"2020-09-01T16:40:10.843442Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1655444162684,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Lg6DNFOZ1aLD","outputId":"1503d8aa-e397-47f7-c96e-72548ce116aa"},"outputs":[{"data":{"text/plain":["[('the', 289838),\n"," (',', 275296),\n"," ('.', 236843),\n"," ('and', 156483),\n"," ('a', 156282),\n"," ('of', 144055),\n"," ('to', 133886),\n"," ('is', 109095),\n"," ('in', 87676),\n"," ('I', 77546)]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.freqs.most_common(10)\n","# TEXT.vocab.stoi\n","# TEXT.vocab.itos"]},{"cell_type":"code","execution_count":11,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.899961Z","start_time":"2020-09-01T16:40:10.885959Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1655444167427,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"EfssHS581aLD","outputId":"57b5c5a8-b996-402b-e572-4f3b00d29ba6"},"outputs":[{"data":{"text/plain":["['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["TEXT.vocab.itos[:10]"]},{"cell_type":"code","execution_count":12,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.915962Z","start_time":"2020-09-01T16:40:10.900958Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1655444172833,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"y0pl1I7K1aLD","outputId":"15d46548-750b-4f2c-fabf-f8ae12517509"},"outputs":[{"data":{"text/plain":["defaultdict(None, {'neg': 0, 'pos': 1})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["LABEL.vocab.stoi"]},{"cell_type":"markdown","metadata":{"id":"2RheZpDK1aLD"},"source":["El √∫ltimo paso para tener nuestros datos listos para entrenar una red neuronal es construir el `DataLoader` encargado de alimentar nuestra red con *batches* de frases de manera eficiente. Para ello utilizamos la clase `torchtext.data.BucketIterator`, que adem√°s juntar√° frases de similar longitud minimazndo el *padding* necesario."]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.947957Z","start_time":"2020-09-01T16:40:10.916958Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1655444202139,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"Ml7Nv-Eu1aLE","outputId":"694b1f18-e815-494e-c7fe-9a12add10a7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","\n","dataloader = {\n","    'train': data.BucketIterator(train_data, batch_size=128, shuffle=True, sort_within_batch=True, device=device),\n","    'test': data.BucketIterator(test_data, batch_size=128, device=device)\n","}"]},{"cell_type":"markdown","metadata":{"id":"ouJM_T9a1aLE"},"source":["## El modelo"]},{"cell_type":"markdown","metadata":{"id":"-cfFgRSx1aLE"},"source":["Para poder clasificar texto utilizaremos una [red recurrente](https://sensioai.com/blog/034_rnn_intro) de tipo `many-to-one`, la cual recibir√° el texto palabra por palabra. Usaremos el √∫ltimo estado oculto (el cual contendr√° informaci√≥n de toda la frase) para generar nuestra predicci√≥n final. Cada palabra estar√° representada por un vector, el cual ser√° aprendido por la red en la capa `embedding` (puedes aprender m√°s sobre esta capa en nuestro [post](https://sensioai.com/blog/037_charRNN) anterior)."]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:10.963957Z","start_time":"2020-09-01T16:40:10.948957Z"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1655444221340,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"rJNO9kOZ1aLE"},"outputs":[],"source":["class RNN(torch.nn.Module):\n","    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=2, num_layers=2, dropout=0.2, bidirectional=False):\n","        super().__init__()\n","        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n","        self.rnn = torch.nn.GRU(\n","            input_size=embedding_dim, \n","            hidden_size=hidden_dim, \n","            num_layers=num_layers, \n","            dropout=dropout if num_layers > 1 else 0,\n","            bidirectional=bidirectional\n","        )\n","        self.fc = torch.nn.Linear(2*hidden_dim if bidirectional else hidden_dim, output_dim)\n","        \n","    def forward(self, text):\n","        #text = [sent len, batch size]        \n","        embedded = self.embedding(text)        \n","        #embedded = [sent len, batch size, emb dim]        \n","        output, hidden = self.rnn(embedded)        \n","        #output = [sent len, batch size, hid dim]\n","        y = self.fc(output[-1,:,:].squeeze(0))     \n","        return y"]},{"cell_type":"markdown","metadata":{"id":"1K_4JoIv1aLF"},"source":["> üí° A diferencia de los pots anteriores, ahora la dimensi√≥n *batch* NO es la primera. Este es el comportamiento por defecto de las capas recurrentes en `Pytorch`. Puedes modificar esto a√±adiendo la opci√≥n `batch_first=True` en la capa recurrente (y aseg√∫rate que tu dataloader utiliza tambi√©n la primera dimensi√≥n para el batch. En `torchtext` puedes indicarlo con el par√°metro `batch_first=True` a la hora de definir el `FIELD` en cuesti√≥n). "]},{"cell_type":"markdown","metadata":{"id":"VodE6Tds1aLF"},"source":["Como siempre, probamos que nuestra red est√© bien definida y las dimensiones encajen. A la entrada, esperamos tensores con dimensiones `longitud secuencia x batch`. Puedes verlo si sacamos unas muestras de nuestro dataloader."]},{"cell_type":"code","execution_count":15,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.126961Z","start_time":"2020-09-01T16:40:10.964958Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3916,"status":"ok","timestamp":1655444274520,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"ppg4-u4D1aLG","outputId":"b1cf6539-17ef-4b22-ef4f-5a192d82cb68"},"outputs":[{"data":{"text/plain":["torch.Size([349, 128])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["batch = next(iter(dataloader['train']))\n","\n","batch.text.shape"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1655444873317,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"_oXNdt-jLtet","outputId":"6d2cf78d-3aef-4585-b701-b5306cf71f96"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([  11,   73,  819,    8,  959,   16,   28,  131, 5971,    3,   26,   19,\n","         232,   21,    2, 1009,    3,   44,    3,   20,    6, 1014, 3113,    3,\n","         716, 7824, 6030, 1606,    5, 3318, 1331,   21,    2,  957,   14,    0,\n","          88,  291,   60,    3,   26,  156,  172,   33,   10,    2, 1355,   23,\n","          13,   22,    4,   14, 4716,    0,    2,   14,    0,    0, 1192,    0,\n","          18, 3011,    3,   11,  276,    0,  503,    0,    6,  274,  777,   22,\n","           4,  555, 1292, 1049, 2725,    3,   12,   85,   34,  410,    7,  277,\n","           5,    6,  186,  488,   55, 1332,  410,    4,   11,   19, 8623,   21,\n","           2,  211,   13,   12,   19,    6, 1047,    3,    5,   20,    6, 1014,\n","        3113,  130,  117,  285,    8, 3085,   13,  211,    5,  130,  109,   28,\n","          79,  218, 5432, 1077,    4,  764, 7298, 1477,   10,    6, 2041,    5,\n","        1489, 2103,   20,    6,    0, 2375,    0,   13,    3,   23,    2,  105,\n","         197,  338,   84, 1570,  127,  213,   88,  529,    4,   63,   30,  212,\n","         240,   36,  147,   76,  614, 7298,  295,   10,    6,  756,  713,  909,\n","        2103,   58,    5,  327,    4,  558,   57,   45,  107, 1252,    0,   13,\n","         191,  178,    5, 8561,    3,    5,  111,  744,   57,   45, 8081,  142,\n","          58,   25,  196,    3,   42,  512,  174,   10,   79,  218,  233,    3,\n","         295,   10,    6,  103,  316,    3,    5,   31,   93,    2, 1401,   13,\n","          45,   73,    6,   60,   68,  808,  328,   71,    9, 1049,  700,   10,\n","           6,   22,   47,   16,    4, 5344,    8,  151,   42,   85,   33,  167,\n","          20, 4531,   10,   16,   22,    3,  247,  129,   17, 1658,    5,  514,\n","          17, 1658,    3,   26,   12,  104,   84, 1013,   55,    2,  342,  966,\n","           5, 1223,  176,    2,  220,    3,   48,   11, 1223,   12,    6, 1068,\n","          39, 6640,   16,   38,   23,    6,   60,   68,    3,  451, 4605,    6,\n","         186,  396,    5,    6,    0,    4,   31,  264,   34,    6,   60, 1783,\n","          18,    0,   18, 2656,    6,  538, 1032,    3,    2,  847,    9, 2162,\n","           4,   54,   15,  103,    8,  860,    2,  257,  507, 2662,    0,    0,\n","         362,    3,    5,   12,  338,   84,    0,    0,    7,    2,  642,  222,\n","         139,    2,  942, 5268,    4,    1,    1,    1,    1,    1,    1,    1,\n","           1], device='cuda:0')\n"]}],"source":["print(batch.text[:, 127])"]},{"cell_type":"markdown","metadata":{"id":"BszMI43L1aLG"},"source":["Cada palabra estr√° representada por un √≠ndice, que luego el `embedding` usar√° para extraer el vector determinado que representa la palabra. A la salida, nuestro modelo nos dar√° dos valores. Si el primer valor es mayor que el segundo, asignaremos la clase `0` (opini√≥n negativa) y viceversa."]},{"cell_type":"code","execution_count":27,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.254958Z","start_time":"2020-09-01T16:40:12.127961Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1655444898684,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"0N81nFz61aLG","outputId":"cb55535f-f06c-4563-afd8-6281634cc180"},"outputs":[{"data":{"text/plain":["torch.Size([64, 2])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["model = RNN(input_dim=len(TEXT.vocab))\n","outputs = model(torch.randint(0, len(TEXT.vocab), (100, 64)))\n","outputs.shape"]},{"cell_type":"markdown","metadata":{"id":"Uz0cz_Pl1aLG"},"source":["## Entrenamiento"]},{"cell_type":"markdown","metadata":{"id":"UMEP9r8f1aLH"},"source":["Para entrenar nuestra red usamos el bucle est√°ndar que ya usamos en posts anteriores."]},{"cell_type":"code","execution_count":28,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:40:12.270961Z","start_time":"2020-09-01T16:40:12.256959Z"},"code_folding":[],"executionInfo":{"elapsed":278,"status":"ok","timestamp":1655444905379,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"d3hf2Ns-1aLH"},"outputs":[],"source":["from tqdm import tqdm\n","import numpy as np\n","\n","def fit(model, dataloader, epochs=5):\n","    model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        train_loss, train_acc = [], []\n","        bar = tqdm(dataloader['train'])\n","        for batch in bar:\n","            X, y = batch.text, batch.label\n","            X, y = X.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(X)\n","            loss = criterion(y_hat, y)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss.append(loss.item())\n","            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","            train_acc.append(acc)\n","            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n","        bar = tqdm(dataloader['test'])\n","        val_loss, val_acc = [], []\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in bar:\n","                X, y = batch.text, batch.label\n","                X, y = X.to(device), y.to(device)\n","                y_hat = model(X)\n","                loss = criterion(y_hat, y)\n","                val_loss.append(loss.item())\n","                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","                val_acc.append(acc)\n","                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n","        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"]},{"cell_type":"code","execution_count":29,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:22.941249Z","start_time":"2020-09-01T16:34:05.448274Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104260,"status":"ok","timestamp":1655445015624,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"NAozFomA1aLH","outputId":"a249dff8-082b-4686-e348-c0aaf6e55cf0"},"outputs":[{"name":"stderr","output_type":"stream","text":["loss 0.66552 acc 0.58906: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:09<00:00, 20.57it/s]\n","val_loss 0.71261 val_acc 0.50197: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:11<00:00, 17.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5 loss 0.66552 val_loss 0.71261 acc 0.58906 val_acc 0.50197\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.52902 acc 0.73838: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:09<00:00, 20.82it/s]\n","val_loss 1.11421 val_acc 0.50759: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:11<00:00, 17.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/5 loss 0.52902 val_loss 1.11421 acc 0.73838 val_acc 0.50759\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.40182 acc 0.82474: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:09<00:00, 20.64it/s]\n","val_loss 0.36842 val_acc 0.84211: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:11<00:00, 17.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/5 loss 0.40182 val_loss 0.36842 acc 0.82474 val_acc 0.84211\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.28718 acc 0.88057: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:09<00:00, 20.77it/s]\n","val_loss 0.31013 val_acc 0.87338: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:11<00:00, 17.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/5 loss 0.28718 val_loss 0.31013 acc 0.88057 val_acc 0.87338\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.23763 acc 0.90740: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:09<00:00, 20.80it/s]\n","val_loss 0.27751 val_acc 0.88396: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:11<00:00, 17.22it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/5 loss 0.23763 val_loss 0.27751 acc 0.90740 val_acc 0.88396\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["fit(model, dataloader)"]},{"cell_type":"markdown","metadata":{"id":"DDA6J8a71aLH"},"source":["## Generando predicciones"]},{"cell_type":"markdown","metadata":{"id":"phO7Cjel1aLI"},"source":["Ahora ya podemos utilizar nuestro modelo para generar valoraciones de manera autom√°tica dada una opini√≥n."]},{"cell_type":"code","execution_count":30,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:23.366252Z","start_time":"2020-09-01T16:36:22.942250Z"},"executionInfo":{"elapsed":620,"status":"ok","timestamp":1655445785047,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"_ZXaSu7H1aLI"},"outputs":[],"source":["import spacy\n","nlp = spacy.load('en')\n","\n","def predict(model, X):\n","    model.eval() \n","    with torch.no_grad():\n","        X = torch.tensor(X).to(device)\n","        pred = model(X)\n","        return pred"]},{"cell_type":"code","execution_count":31,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:23.382248Z","start_time":"2020-09-01T16:36:23.367255Z"},"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1655445787316,"user":{"displayName":"Carlos Walter Pacheco Lora","userId":"05889892519883337793"},"user_tz":240},"id":"1Svs5FC_1aLI","outputId":"3e3c5955-e98a-42a4-825e-ad4184cd71ca"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n"]},{"data":{"text/plain":["tensor([0, 1, 1, 0, 0], device='cuda:0')"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\", \"I hate it.\"]\n","tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n","indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n","tensor = torch.tensor(indexed).permute(1,0)\n","predictions = torch.argmax(predict(model, tensor), axis=1)\n","predictions"]},{"cell_type":"markdown","metadata":{"id":"Xps6nej_1aLI"},"source":["En este caso solo tenemos dos posibles clases, pero es f√°cil intuir que de ser capaces de construir un dataset con muchas m√°s clases que describan con mayor precisi√≥n el \"sentimiento\" en un texto podr√≠amos extraer much√≠sima informaci√≥n muy valiosa para, sobre todo, empresas que venden productos online m√°s all√° de las t√≠picas estrellas o puntuaciones que, pese a dar informaci√≥n valiosa, no aportan ning√∫n tipo de informaci√≥n accionable."]},{"cell_type":"markdown","metadata":{"id":"3875mz_T1aLI"},"source":["## Redes Recurrentes Bidireccionales"]},{"cell_type":"markdown","metadata":{"id":"OpHNbNgF1aLJ"},"source":["Las redes recurrentes bidireccionales nos van a permitir, por norma general, obtener mejores resultados cuando trabajemos con datos secuenciales en los que \"podamos mirar al futuro\". En aplicaciones tales como la generaci√≥n de texto o la predicci√≥n de series temporales, esto no lo pod√≠amos hacer ya que el objetivo de la tarea es precisamente predecir valores futuros (y utilizar estos valores durante el entrenamiento no tendr√≠a sentido). Sin embargo, para la tarea de clasificaci√≥n de texto, s√≠ que podemos hacerlo.\n","\n","![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)\n","\n","Puedes conocer m√°s sobre este tipo de redes, as√≠ como otras mejoras, en este [post](https://sensioai.com/blog/036_rnn_mejoras)."]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"start_time":"2020-09-01T16:39:19.400Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"1wBGQVIx1aLJ","outputId":"b7800469-338e-4783-f01c-f1aa0c8d2fd3"},"outputs":[{"name":"stderr","output_type":"stream","text":["loss 0.65129 acc 0.60130: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:16<00:00, 11.58it/s]\n","val_loss 0.63835 val_acc 0.52760: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:18<00:00, 10.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5 loss 0.65129 val_loss 0.63835 acc 0.60130 val_acc 0.52760\n"]},{"name":"stderr","output_type":"stream","text":["loss 0.47277 acc 0.78142:  23%|‚ñà‚ñà‚ñé       | 45/196 [00:03<00:11, 12.85it/s]"]}],"source":["model = RNN(input_dim=len(TEXT.vocab), bidirectional=True)\n","fit(model, dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2020-09-01T16:36:23.382248Z","start_time":"2020-09-01T16:36:23.367255Z"},"id":"QbfZybjuo5fO"},"outputs":[],"source":["sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\", \"so good bad film\", \"so little bad good\"]\n","tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n","indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n","tensor = torch.tensor(indexed).permute(1,0)\n","predictions = torch.argmax(predict(model, tensor), axis=1)\n","predictions"]},{"cell_type":"markdown","metadata":{"id":"fHajFJBc1aLJ"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"M32ASRDl1aLJ"},"source":["En este post hemos aprendido a utilizar `redes neuronales recurrentes` para la tarea de clasificaci√≥n de texto. Esta tarea es muy √∫til en la industria, sobre todo para aquellos negocios que venden productos o servicios cuyos usuarios pueden valorar directamente de manera online de forma masiva. Tener un sistema automatizado que \"lea\" todas las opiniones y las clasifique en clases con significado, puede aportar mucha informaci√≥n valiosa a una empresa sobre la cual puede llevar a cabo acciones de mejora de manera r√°pida. Como hemos visto, el uso de la librer√≠a `torchtext` nos facilita mucho la vida a la hora de procesar el texto, y gracias a su integraci√≥n con `Pytorch` podremos entrenar modelos de manera r√°pida y sencilla. Para esta tarea en concreto, tambi√©n hemos visto que el uso de `redes recurrentes bidireccionales` nos puede dar un extra de precisi√≥n."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"clasificacion_texto.ipynb","provenance":[{"file_id":"https://github.com/juansensio/blog/blob/master/038_clasificacion_texto/clasificacion_texto.ipynb","timestamp":1623377428250}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}
